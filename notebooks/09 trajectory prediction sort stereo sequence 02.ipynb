{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc88dc5b",
   "metadata": {},
   "source": [
    "## 00 configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f47107e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\r\n",
      "#\r\n",
      "base                     /home/theekshana/anaconda3\r\n",
      "YOLO3D                *  /home/theekshana/anaconda3/envs/YOLO3D\r\n",
      "sr                       /home/theekshana/anaconda3/envs/sr\r\n",
      "stereo_rcnn              /home/theekshana/anaconda3/envs/stereo_rcnn\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb93c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append(\"../\")\n",
    "import importlib\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import cython\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e800b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualDet3D.data.kitti.utils import write_result_to_file\n",
    "from visualDet3D.utils.utils import LossLogger, cfg_from_file\n",
    "from visualDet3D.networks.utils.registry import DETECTOR_DICT, DATASET_DICT, PIPELINE_DICT\n",
    "from visualDet3D.networks.heads.anchors import Anchors\n",
    "from visualDet3D.networks.lib.fast_utils.hill_climbing import post_opt\n",
    "from visualDet3D.networks.utils import BBox3dProjector, BackProjection\n",
    "from visualDet3D.utils.utils import convertAlpha2Rot, convertRot2Alpha, draw_3D_box, compound_annotation\n",
    "import visualDet3D.data.kitti.dataset\n",
    "from visualDet3D.utils.timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88e89f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "cfg = cfg_from_file(\"config/config.py\")\n",
    "is_test_train = True\n",
    "\n",
    "checkpoint_name = \"Stereo3D_latest.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00465635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Conifg File\n",
    "cfg.batch_size=1\n",
    "split_to_test='validation'\n",
    "\n",
    "# Define dataset_name\n",
    "is_test_train = split_to_test == 'training'\n",
    "if split_to_test == 'training':\n",
    "    dataset_name = cfg.data.train_dataset\n",
    "elif split_to_test == 'test':\n",
    "    dataset_name = cfg.data.test_dataset\n",
    "else:\n",
    "    dataset_name = cfg.data.val_dataset\n",
    "\n",
    "# Make dataset\n",
    "dataset = DATASET_DICT[dataset_name](\n",
    "        cfg, split_to_test\n",
    "        )\n",
    "\n",
    "# Split train/validation data\n",
    "if split_to_test=='training':\n",
    "    dataset_val = DATASET_DICT[cfg.data.val_dataset](\n",
    "            cfg, 'validation'\n",
    "            )\n",
    "    dataset.transform = dataset_val.transform\n",
    "    dataset.collate_fn = dataset_val.collate_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af82901",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build a detector network\n",
    "detector = DETECTOR_DICT[cfg.detector.name](cfg.detector)\n",
    "detector = detector.cuda()\n",
    "\n",
    "# Tensor load by GPU\n",
    "weight_path = os.path.join(cfg.path.checkpoint_path, checkpoint_name)\n",
    "state_dict = torch.load(weight_path, map_location='cuda:{}'.format(cfg.trainer.gpu))\n",
    "new_dict = state_dict.copy()\n",
    "for key in state_dict:\n",
    "    if 'focalLoss' in key:\n",
    "        new_dict.pop(key)\n",
    "\n",
    "# Load the pre-trained model\n",
    "detector.load_state_dict(new_dict, strict=False)\n",
    "detector.eval().cuda()\n",
    "\n",
    "# Testing pipeline\n",
    "test_func = PIPELINE_DICT[cfg.trainer.test_func]\n",
    "\n",
    "# Load projector and backprojector\n",
    "projector = BBox3dProjector().cuda()\n",
    "backprojector = BackProjection().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95be153",
   "metadata": {},
   "source": [
    "## 01 YOLO3D objext detection and bounding box estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5afd1cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox2d_to_image(image, bboxes2d, color=(255, 0, 255)):\n",
    "    drawed_image = image.copy()\n",
    "    for box2d in bboxes2d:\n",
    "        cv2.rectangle(drawed_image, (int(box2d[0]), int(box2d[1])), (int(box2d[2]), int(box2d[3])), color, 3)\n",
    "    return drawed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed2814c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "def corner_homo2bbox(corner_homo):\n",
    "    \"\"\"\n",
    "        corner_homo: [N, 8, 3]\n",
    "    \"\"\"\n",
    "    min_xy  = torch.min(corner_homo[:, :, 0:2], dim=1)[0]\n",
    "    max_xy  = torch.max(corner_homo[:, :, 0:2], dim=1)[0]\n",
    "    min_xy[:, 0]  = torch.clamp(min_xy[:, 0], 0, cfg.rgb_shape[1])\n",
    "    min_xy[:, 1]  = torch.clamp(min_xy[:, 1], 0, cfg.rgb_shape[0])\n",
    "    max_xy[:, 0]  = torch.clamp(max_xy[:, 0], 0, cfg.rgb_shape[1])\n",
    "    max_xy[:, 1]  = torch.clamp(max_xy[:, 1], 0, cfg.rgb_shape[0])\n",
    "    return torch.cat([min_xy, max_xy], dim=1)\n",
    "\n",
    "def denorm(image):\n",
    "    new_image = np.array((image * cfg.data.augmentation.rgb_std +  cfg.data.augmentation.rgb_mean) * 255, dtype=np.uint8)\n",
    "    return new_image\n",
    "\n",
    "@jit(cache=True, nopython=True)\n",
    "def ToColorDepth(depth_image:np.ndarray)->np.ndarray: #[H, W] -> [H, W, 3] # Used to draw depth predictions\n",
    "    H, W = depth_image.shape\n",
    "    max_depth = float(np.max(depth_image))\n",
    "    cmap = np.array([\n",
    "        [0,0,0,114],[0,0,1,185],[1,0,0,114],[1,0,1,174], \n",
    "        [0,1,0,114],[0,1,1,185],[1,1,0,114],[1,1,1,0]\n",
    "    ])\n",
    "    _sum  = 0\n",
    "    for i in range(8):\n",
    "        _sum += cmap[i, 3]\n",
    "    \n",
    "    weights = np.zeros(8)\n",
    "    cumsum = np.zeros(8)\n",
    "    for i in range(7):\n",
    "        weights[i] = _sum / cmap[i, 3]\n",
    "        cumsum[i+1] = cumsum[i] + cmap[i, 3] / _sum\n",
    "    \n",
    "    image = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            val = depth_image[i, j] / max_depth\n",
    "            for k in range(7):\n",
    "                if val <= cumsum[k + 1]:\n",
    "                    break\n",
    "            w = 1.0- (val - cumsum[k]) * weights[k]\n",
    "            r = int( (w * cmap[k, 0] + (1 - w) * cmap[k+1, 0]) * 255 )\n",
    "            g = int( (w * cmap[k, 1] + (1 - w) * cmap[k+1, 1]) * 255 )\n",
    "            b = int( (w * cmap[k, 2] + (1 - w) * cmap[k+1, 2]) * 255 )\n",
    "            image[i, j] = np.array([r,g,b])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a21cdd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_once(index, is_draw=True, is_test_train=True):\n",
    "    name = \"%06d\" % index\n",
    "#     print(name)\n",
    "    data = dataset[index]\n",
    "    if isinstance(data['calib'], list):\n",
    "        P2 = data['calib'][0]\n",
    "    else:\n",
    "        P2 = data['calib']\n",
    "    original_height = data['original_shape'][0]\n",
    "    collated_data = dataset.collate_fn([data])\n",
    "    height = collated_data[0].shape[2]\n",
    "    scale_2d = (original_height - cfg.data.augmentation.crop_top) / height\n",
    "    \n",
    "    if len(collated_data) > 6:\n",
    "        left_images, right_images, _, _, labels, bbox_3d, _ = collated_data\n",
    "    else:\n",
    "        left_images, right_images, _, _, labels, bbox_3d = collated_data\n",
    "    image = left_images\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        left_images, right_images, P2, P3 = collated_data[0], collated_data[1], collated_data[2], collated_data[3]\n",
    "        scores, bbox, obj_names = detector([left_images.cuda().float().contiguous(),\n",
    "                                          right_images.cuda().float().contiguous(),\n",
    "                                          P2.cuda().float(),\n",
    "                                          P3.cuda().float()])\n",
    "        \n",
    "        P2 = P2[0]\n",
    "        bbox_2d = bbox[:, 0:4]\n",
    "        bbox_3d_state = bbox[:, 4:] #[cx,cy,z,w,h,l,alpha]\n",
    "        bbox_3d_state_3d = backprojector(bbox_3d_state, P2.cuda()) #[x, y, z, w,h ,l, alpha]\n",
    "        abs_bbox, bbox_3d_corner_homo, thetas = projector(bbox_3d_state_3d, P2.cuda())\n",
    "\n",
    "            \n",
    "    \n",
    "    rgb_image = denorm(image[0].cpu().numpy().transpose([1, 2, 0]))\n",
    "    if len(scores) > 0:\n",
    "        rgb_image = draw_bbox2d_to_image(rgb_image, bbox_2d.cpu().numpy())\n",
    "        for box in bbox_3d_corner_homo:\n",
    "            box = box.cpu().numpy().T\n",
    "            rgb_image = draw_3D_box(rgb_image, box)\n",
    "    if is_draw:\n",
    "        plt.imshow(np.clip(rgb_image, 0, 255))\n",
    "        plt.show()\n",
    "\n",
    "    return np.clip(rgb_image, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be415d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_once_3d_bounding_box_only(index, is_draw=True, is_test_train=True):\n",
    "    name = \"%06d\" % index\n",
    "#     print(name)\n",
    "    data = dataset[index]\n",
    "    if isinstance(data['calib'], list):\n",
    "        P2 = data['calib'][0]\n",
    "    else:\n",
    "        P2 = data['calib']\n",
    "    original_height = data['original_shape'][0]\n",
    "    collated_data = dataset.collate_fn([data])\n",
    "    height = collated_data[0].shape[2]\n",
    "    scale_2d = (original_height - cfg.data.augmentation.crop_top) / height\n",
    "    \n",
    "    if len(collated_data) > 6:\n",
    "        left_images, right_images, _, _, labels, bbox_3d, _ = collated_data\n",
    "    else:\n",
    "        left_images, right_images, _, _, labels, bbox_3d = collated_data\n",
    "    image = left_images\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        left_images, right_images, P2, P3 = collated_data[0], collated_data[1], collated_data[2], collated_data[3]\n",
    "        scores, bbox, obj_names = detector([left_images.cuda().float().contiguous(),\n",
    "                                          right_images.cuda().float().contiguous(),\n",
    "                                          P2.cuda().float(),\n",
    "                                          P3.cuda().float()])\n",
    "        \n",
    "        P2 = P2[0]\n",
    "        bbox_2d = bbox[:, 0:4]\n",
    "        bbox_3d_state = bbox[:, 4:] #[cx,cy,z,w,h,l,alpha]\n",
    "        bbox_3d_state_3d = backprojector(bbox_3d_state, P2.cuda()) #[x, y, z, w,h ,l, alpha]\n",
    "        abs_bbox, bbox_3d_corner_homo, thetas = projector(bbox_3d_state_3d, P2.cuda())\n",
    "\n",
    "            \n",
    "    \n",
    "    rgb_image = denorm(image[0].cpu().numpy().transpose([1, 2, 0]))\n",
    "    if len(scores) > 0:\n",
    "        \n",
    "        for box in bbox_3d_corner_homo:\n",
    "            box = box.cpu().numpy().T\n",
    "            rgb_image = draw_3D_box(rgb_image, box)\n",
    "    if is_draw:\n",
    "        plt.imshow(np.clip(rgb_image, 0, 255))\n",
    "        \n",
    "\n",
    "    return np.clip(rgb_image, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b8d7bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_3d_boxes(index):\n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    a = compute_once_3d_bounding_box_only(index, is_test_train=False, is_draw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ba5402",
   "metadata": {},
   "source": [
    "### 2D + 3D bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f546653e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #%matplotlib inline\n",
    "# fig = plt.figure(figsize=(16,9))\n",
    "# index = 2\n",
    "# a = compute_once(index, is_test_train=False, is_draw=True)\n",
    "# # print(index,cv2.imwrite(('data/2d3d %02d.png'%index), cv2.cvtColor(a, cv2.COLOR_RGB2BGR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f7f3f0",
   "metadata": {},
   "source": [
    "### 3D bounding boxes Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eee087f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_3d_boxes(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c679c1c",
   "metadata": {},
   "source": [
    "## 02 Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "457b6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5cab269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09fbd325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(index):\n",
    "    name = \"%06d\" % index\n",
    "    data = dataset[index]\n",
    "    if isinstance(data['calib'], list):\n",
    "        P2 = data['calib'][0]\n",
    "    else:\n",
    "        P2 = data['calib']\n",
    "    original_height = data['original_shape'][0]\n",
    "    collated_data = dataset.collate_fn([data])\n",
    "    height = collated_data[0].shape[2]\n",
    "    scale_2d = (original_height - cfg.data.augmentation.crop_top) / height\n",
    "    \n",
    "    if len(collated_data) > 6:\n",
    "        left_images, right_images, _, _, labels, bbox_3d, _ = collated_data\n",
    "    else:\n",
    "        left_images, right_images, _, _, labels, bbox_3d = collated_data\n",
    "    image = left_images\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        left_images, right_images, P2, P3 = collated_data[0], collated_data[1], collated_data[2], collated_data[3]\n",
    "        scores, bbox, obj_names = detector([left_images.cuda().float().contiguous(),\n",
    "                                          right_images.cuda().float().contiguous(),\n",
    "                                          P2.cuda().float(),\n",
    "                                          P3.cuda().float()])\n",
    "        \n",
    "        P2 = P2[0]\n",
    "        bbox_2d = bbox[:, 0:4]\n",
    "        bbox_3d_state = bbox[:, 4:] #[cx,cy,z,w,h,l,alpha]\n",
    "        bbox_3d_state_3d = backprojector(bbox_3d_state, P2.cuda()) #[x, y, z, w,h ,l, alpha]\n",
    "        abs_bbox, bbox_3d_corner_homo, thetas = projector(bbox_3d_state_3d, P2.cuda())\n",
    "        \n",
    "        rgb_image = denorm(image[0].cpu().numpy().transpose([1, 2, 0]))\n",
    "        \n",
    "        return rgb_image, scores, bbox_2d, obj_names, bbox_3d_corner_homo\n",
    "    \n",
    "#     if len(scores) > 0:\n",
    "#         rgb_image = draw_bbox2d_to_image(rgb_image, bbox_2d.cpu().numpy())\n",
    "#         for box in bbox_3d_corner_homo:\n",
    "#             box = box.cpu().numpy().T\n",
    "#             rgb_image = draw_3D_box(rgb_image, box)\n",
    "#     if is_draw:\n",
    "#         plt.imshow(np.clip(rgb_image, 0, 255))\n",
    "        \n",
    "#     return np.clip(rgb_image, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e9bfbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    SORT: A Simple, Online and Realtime Tracker\n",
    "    Copyright (C) 2016-2020 Alex Bewley alex@bewley.ai\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the GNU General Public License\n",
    "    along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.patches as patches\n",
    "from skimage import io\n",
    "\n",
    "import glob\n",
    "import time\n",
    "import argparse\n",
    "from filterpy.kalman import KalmanFilter\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8da0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_assignment(cost_matrix):\n",
    "  try:\n",
    "    import lap\n",
    "    _, x, y = lap.lapjv(cost_matrix, extend_cost=True)\n",
    "    return np.array([[y[i],i] for i in x if i >= 0]) #\n",
    "  except ImportError:\n",
    "    from scipy.optimize import linear_sum_assignment\n",
    "    x, y = linear_sum_assignment(cost_matrix)\n",
    "    return np.array(list(zip(x, y)))\n",
    "\n",
    "\n",
    "def iou_batch(bb_test, bb_gt):\n",
    "  \"\"\"\n",
    "  From SORT: Computes IOU between two bboxes in the form [x1,y1,x2,y2]\n",
    "  \"\"\"\n",
    "  bb_gt = np.expand_dims(bb_gt, 0)\n",
    "  bb_test = np.expand_dims(bb_test, 1)\n",
    "  \n",
    "  xx1 = np.maximum(bb_test[..., 0], bb_gt[..., 0])\n",
    "  yy1 = np.maximum(bb_test[..., 1], bb_gt[..., 1])\n",
    "  xx2 = np.minimum(bb_test[..., 2], bb_gt[..., 2])\n",
    "  yy2 = np.minimum(bb_test[..., 3], bb_gt[..., 3])\n",
    "  w = np.maximum(0., xx2 - xx1)\n",
    "  h = np.maximum(0., yy2 - yy1)\n",
    "  wh = w * h\n",
    "  o = wh / ((bb_test[..., 2] - bb_test[..., 0]) * (bb_test[..., 3] - bb_test[..., 1])                                      \n",
    "    + (bb_gt[..., 2] - bb_gt[..., 0]) * (bb_gt[..., 3] - bb_gt[..., 1]) - wh)                                              \n",
    "  return(o)  \n",
    "\n",
    "\n",
    "def convert_bbox_to_z(bbox):\n",
    "  \"\"\"\n",
    "  Takes a bounding box in the form [x1,y1,x2,y2] and returns z in the form\n",
    "    [x,y,s,r] where x,y is the centre of the box and s is the scale/area and r is\n",
    "    the aspect ratio\n",
    "  \"\"\"\n",
    "  w = bbox[2] - bbox[0]\n",
    "  h = bbox[3] - bbox[1]\n",
    "  x = bbox[0] + w/2.\n",
    "  y = bbox[1] + h/2.\n",
    "  s = w * h    #scale is just area\n",
    "  r = w / float(h)\n",
    "  return np.array([x, y, s, r]).reshape((4, 1))\n",
    "\n",
    "\n",
    "def convert_x_to_bbox(x,score=None):\n",
    "  \"\"\"\n",
    "  Takes a bounding box in the centre form [x,y,s,r] and returns it in the form\n",
    "    [x1,y1,x2,y2] where x1,y1 is the top left and x2,y2 is the bottom right\n",
    "  \"\"\"\n",
    "  w = np.sqrt(x[2] * x[3])\n",
    "  h = x[2] / w\n",
    "  if(score==None):\n",
    "    return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.]).reshape((1,4))\n",
    "  else:\n",
    "    return np.array([x[0]-w/2.,x[1]-h/2.,x[0]+w/2.,x[1]+h/2.,score]).reshape((1,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61d6667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanBoxTracker(object):\n",
    "  \"\"\"\n",
    "  This class represents the internal state of individual tracked objects observed as bbox.\n",
    "  \"\"\"\n",
    "  count = 0\n",
    "  def __init__(self,bbox):\n",
    "    \"\"\"\n",
    "    Initialises a tracker using initial bounding box.\n",
    "    \"\"\"\n",
    "    #define constant velocity model\n",
    "    self.kf = KalmanFilter(dim_x=7, dim_z=4) \n",
    "    self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n",
    "    self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n",
    "\n",
    "    self.kf.R[2:,2:] *= 10.\n",
    "    self.kf.P[4:,4:] *= 1000. #give high uncertainty to the unobservable initial velocities\n",
    "    self.kf.P *= 10.\n",
    "    self.kf.Q[-1,-1] *= 0.01\n",
    "    self.kf.Q[4:,4:] *= 0.01\n",
    "\n",
    "    self.kf.x[:4] = convert_bbox_to_z(bbox)\n",
    "    self.time_since_update = 0\n",
    "    self.id = KalmanBoxTracker.count\n",
    "    KalmanBoxTracker.count += 1\n",
    "    self.history = []\n",
    "    self.hits = 0\n",
    "    self.hit_streak = 0\n",
    "    self.age = 0\n",
    "\n",
    "  def update(self,bbox):\n",
    "    \"\"\"\n",
    "    Updates the state vector with observed bbox.\n",
    "    \"\"\"\n",
    "    self.time_since_update = 0\n",
    "    self.history = []\n",
    "    self.hits += 1\n",
    "    self.hit_streak += 1\n",
    "    self.kf.update(convert_bbox_to_z(bbox))\n",
    "\n",
    "  def predict(self):\n",
    "    \"\"\"\n",
    "    Advances the state vector and returns the predicted bounding box estimate.\n",
    "    \"\"\"\n",
    "    if((self.kf.x[6]+self.kf.x[2])<=0):\n",
    "      self.kf.x[6] *= 0.0\n",
    "    self.kf.predict()\n",
    "    self.age += 1\n",
    "    if(self.time_since_update>0):\n",
    "      self.hit_streak = 0\n",
    "    self.time_since_update += 1\n",
    "    self.history.append(convert_x_to_bbox(self.kf.x))\n",
    "    return self.history[-1]\n",
    "\n",
    "  def get_state(self):\n",
    "    \"\"\"\n",
    "    Returns the current bounding box estimate.\n",
    "    \"\"\"\n",
    "    return convert_x_to_bbox(self.kf.x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d01f277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def associate_detections_to_trackers(detections,trackers,iou_threshold = 0.3):\n",
    "  \"\"\"\n",
    "  Assigns detections to tracked object (both represented as bounding boxes)\n",
    "\n",
    "  Returns 3 lists of matches, unmatched_detections and unmatched_trackers\n",
    "  \"\"\"\n",
    "  if(len(trackers)==0):\n",
    "    return np.empty((0,2),dtype=int), np.arange(len(detections)), np.empty((0,5),dtype=int)\n",
    "\n",
    "  iou_matrix = iou_batch(detections, trackers)\n",
    "\n",
    "  if min(iou_matrix.shape) > 0:\n",
    "    a = (iou_matrix > iou_threshold).astype(np.int32)\n",
    "    if a.sum(1).max() == 1 and a.sum(0).max() == 1:\n",
    "        matched_indices = np.stack(np.where(a), axis=1)\n",
    "    else:\n",
    "      matched_indices = linear_assignment(-iou_matrix)\n",
    "  else:\n",
    "    matched_indices = np.empty(shape=(0,2))\n",
    "\n",
    "  unmatched_detections = []\n",
    "  for d, det in enumerate(detections):\n",
    "    if(d not in matched_indices[:,0]):\n",
    "      unmatched_detections.append(d)\n",
    "  unmatched_trackers = []\n",
    "  for t, trk in enumerate(trackers):\n",
    "    if(t not in matched_indices[:,1]):\n",
    "      unmatched_trackers.append(t)\n",
    "\n",
    "  #filter out matched with low IOU\n",
    "  matches = []\n",
    "  for m in matched_indices:\n",
    "    if(iou_matrix[m[0], m[1]]<iou_threshold):\n",
    "      unmatched_detections.append(m[0])\n",
    "      unmatched_trackers.append(m[1])\n",
    "    else:\n",
    "      matches.append(m.reshape(1,2))\n",
    "  if(len(matches)==0):\n",
    "    matches = np.empty((0,2),dtype=int)\n",
    "  else:\n",
    "    matches = np.concatenate(matches,axis=0)\n",
    "\n",
    "  return matches, np.array(unmatched_detections), np.array(unmatched_trackers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "faa86e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sort(object):\n",
    "  def __init__(self, max_age=1, min_hits=3, iou_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Sets key parameters for SORT\n",
    "    \"\"\"\n",
    "    self.max_age = max_age\n",
    "    self.min_hits = min_hits\n",
    "    self.iou_threshold = iou_threshold\n",
    "    self.trackers = []\n",
    "    self.frame_count = 0\n",
    "\n",
    "  def update(self, dets=np.empty((0, 5))):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "      dets - a numpy array of detections in the format [[x1,y1,x2,y2,score],[x1,y1,x2,y2,score],...]\n",
    "    Requires: this method must be called once for each frame even with empty detections (use np.empty((0, 5)) for frames without detections).\n",
    "    Returns the a similar array, where the last column is the object ID.\n",
    "\n",
    "    NOTE: The number of objects returned may differ from the number of detections provided.\n",
    "    \"\"\"\n",
    "    self.frame_count += 1\n",
    "    # get predicted locations from existing trackers.\n",
    "    trks = np.zeros((len(self.trackers), 5))\n",
    "    to_del = []\n",
    "    ret = []\n",
    "    for t, trk in enumerate(trks):\n",
    "      pos = self.trackers[t].predict()[0]\n",
    "      trk[:] = [pos[0], pos[1], pos[2], pos[3], 0]\n",
    "      if np.any(np.isnan(pos)):\n",
    "        to_del.append(t)\n",
    "    trks = np.ma.compress_rows(np.ma.masked_invalid(trks))\n",
    "    for t in reversed(to_del):\n",
    "      self.trackers.pop(t)\n",
    "    matched, unmatched_dets, unmatched_trks = associate_detections_to_trackers(dets,trks, self.iou_threshold)\n",
    "\n",
    "    # update matched trackers with assigned detections\n",
    "    for m in matched:\n",
    "      self.trackers[m[1]].update(dets[m[0], :])\n",
    "\n",
    "    # create and initialise new trackers for unmatched detections\n",
    "    for i in unmatched_dets:\n",
    "        trk = KalmanBoxTracker(dets[i,:])\n",
    "        self.trackers.append(trk)\n",
    "    i = len(self.trackers)\n",
    "    for trk in reversed(self.trackers):\n",
    "        d = trk.get_state()[0]\n",
    "        if (trk.time_since_update < 1) and (trk.hit_streak >= self.min_hits or self.frame_count <= self.min_hits):\n",
    "          ret.append(np.concatenate((d,[trk.id+1])).reshape(1,-1)) # +1 as MOT benchmark requires positive\n",
    "        i -= 1\n",
    "        # remove dead tracklet\n",
    "        if(trk.time_since_update > self.max_age):\n",
    "          self.trackers.pop(i)\n",
    "    if(len(ret)>0):\n",
    "      return np.concatenate(ret)\n",
    "    return np.empty((0,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7273a26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance of SORT\n",
    "mot_tracker = Sort() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b2efdac6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theekshana/Documents/visualDet3D/visualDet3D/networks/lib/PSM_cost_volume.py:87: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  volatile= not self.training\n",
      "/home/theekshana/Documents/visualDet3D/visualDet3D/networks/lib/PSM_cost_volume.py:55: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  volatile= not self.training\n"
     ]
    }
   ],
   "source": [
    "gb_image, scores, bbox_2d, obj_names, bbox_3d_corner_homo=get_predictions(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5aff44e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[362.53412   88.29793  501.7556   177.12343 ]\n",
      " [710.6368    91.851875 831.34344  194.3847  ]\n",
      " [482.24524   83.02001  548.61316  131.76286 ]\n",
      " [  0.        95.00485  215.50653  223.0947  ]\n",
      " [610.1448    81.69842  643.22974  110.36956 ]\n",
      " [297.88434   81.374954 401.95538  140.64415 ]\n",
      " [652.6979    81.896164 679.8235   105.2977  ]]\n",
      "[0.9994966  0.9988003  0.99692625 0.9940738  0.98690134 0.9851834\n",
      " 0.79079044]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(bbox_2d.cpu()))\n",
    "print(np.asarray(scores.cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24bf53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignTrackID(index):\n",
    "    # get detections\n",
    "    rgb_image, scores, bbox_2d, obj_names, bbox_3d_corner_homo=get_predictions(index)\n",
    "    \n",
    "    if len(scores) > 0:\n",
    "        \n",
    "        detectionsList=[]\n",
    "        for i in range(len(scores)):\n",
    "            detection=np.append((bbox_2d[i]).cpu(),scores[i].cpu())\n",
    "            detectionsList.append(detection)\n",
    "        detectionsNumPyArray = np.asarray(detectionsList)\n",
    "        # update SORT\n",
    "        #  def update(self, dets=np.empty((0, 5))):\n",
    "        \"\"\"\n",
    "            Params:\n",
    "              dets - a numpy array of detections in the format [[x1,y1,x2,y2,score],[x1,y1,x2,y2,score],...]\n",
    "            Requires: this method must be called once for each frame even with empty detections (use np.empty((0, 5)) for frames without detections).\n",
    "            Returns the a similar array, where the last column is the object ID.\n",
    "\n",
    "            NOTE: The number of objects returned may differ from the number of detections provided.\n",
    "        \"\"\"\n",
    "        track_bbs_ids = mot_tracker.update(detectionsNumPyArray)\n",
    "    # track_bbs_ids is a np array where each row contains a valid bounding box and track_id (last column)\n",
    "\n",
    "        for box in bbox_3d_corner_homo:\n",
    "            box = box.cpu().numpy().T\n",
    "            rgb_image = draw_3D_box(rgb_image, box)\n",
    "\n",
    "        track_bbs_ids_list=track_bbs_ids.tolist()\n",
    "        \n",
    "        for j in range(len(track_bbs_ids_list)):\n",
    "            coords = track_bbs_ids_list[j]\n",
    "            x1,y1,x2,y2=int(coords[0]),int(coords[1]),int(coords[2]),int(coords[3])\n",
    "            trackID=int(coords[4])\n",
    "            name=\"ID: {}\".format(str(trackID))\n",
    "\n",
    "            # font\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            # org\n",
    "            org = (x1, y1-10)\n",
    "            # fontScale\n",
    "            fontScale = 0.9\n",
    "            # Line thickness of 2 px\n",
    "            thickness = 2\n",
    "            # Blue color in BGR\n",
    "            color=(0, 255, 255)\n",
    "            text_color_bg=(0, 0, 0)\n",
    "            text_size, _ = cv2.getTextSize(name, font, fontScale, thickness)\n",
    "            text_w, text_h = text_size\n",
    "            cv2.rectangle(rgb_image, (x1 , y1-10 - text_h), (x1 + text_w, y1-10), text_color_bg, -1)\n",
    "            \n",
    "            # Using cv2.putText() method\n",
    "            cv2.putText(rgb_image,name, org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "                \n",
    "# def draw_bbox2d_to_image(image, bboxes2d, color=(255, 0, 255)):\n",
    "#     drawed_image = image.copy()\n",
    "#     for box2d in bboxes2d:\n",
    "#         cv2.rectangle(drawed_image, (int(box2d[0]), int(box2d[1])), (int(box2d[2]), int(box2d[3])), color, 3)\n",
    "#     return drawed_image\n",
    "            \n",
    "    return np.clip(rgb_image, 0, 255), track_bbs_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4981d2f",
   "metadata": {},
   "source": [
    "### 3D bounding boxes + Track ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fd4bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(16,9))\n",
    "# index=0\n",
    "\n",
    "# start = time.time()\n",
    "# a,track_bbs_ids=assignTrackID(index)\n",
    "# end = time.time()\n",
    "\n",
    "# plt.imshow(a)\n",
    "# plt.show()\n",
    "# # Time elapsed\n",
    "# seconds = end - start\n",
    "# print (\"Time taken : {0} seconds\".format(seconds))\n",
    "\n",
    "# # Calculate frames per second\n",
    "# fps  = 1 / seconds\n",
    "# print(\"Estimated frames per second : {0}\".format(fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37fcb88",
   "metadata": {},
   "source": [
    "## 02 Trajectory Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91b0e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(16,9))\n",
    "# index=0\n",
    "\n",
    "# image,track_bbs_ids=assignTrackID(index)\n",
    "# image_o=image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "156eccfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(16,9))\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f21481b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_bb=track_bbs_ids[-1,:-1]\n",
    "# # print(initial_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43dacf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ktp = KalmanBoxTracker(initial_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cd21f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_next_trajectory(image,bb,i):\n",
    "#     bb=bb.astype(int)\n",
    "    xm=int((bb[0]+bb[2])/2)\n",
    "    ym=int((bb[1]+bb[3])/2)\n",
    "     # font\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    # org\n",
    "    org = int(xm),int(ym)\n",
    "    # fontScale\n",
    "    fontScale = 0.9\n",
    "    # Line thickness of 2 px\n",
    "    thickness = 2\n",
    "    # Blue color in BGR\n",
    "    color=(255, 0, 0)\n",
    "    text_color_bg=(0, 0, 0)\n",
    "#     text_size, _ = cv2.getTextSize(name, font, fontScale, thickness)\n",
    "#     text_w, text_h = text_size\n",
    "#     cv2.rectangle(rgb_image, (x1 , y1-10 - text_h), (x1 + text_w, y1-10), text_color_bg, -1)\n",
    "            \n",
    "    # Using cv2.putText() method\n",
    "    name=str(i)\n",
    "    cv2.putText(image,name, org, font, fontScale, color, thickness, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dedb73e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(16,9))\n",
    "# image_c=image.copy()\n",
    "# plt.imshow(image_c)\n",
    "# draw_next_trajectory(image_c,initial_bb,0)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21269b66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theekshana/Documents/visualDet3D/visualDet3D/data/kitti/dataset/stereo_dataset.py:155: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525553989/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  return torch.from_numpy(left_images).float(), torch.from_numpy(right_images).float(), torch.tensor(P2).float(), torch.tensor(P3).float(), label, bbox2ds, bbox3ds\n",
      "/home/theekshana/Documents/visualDet3D/visualDet3D/networks/lib/PSM_cost_volume.py:87: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  volatile= not self.training\n",
      "/home/theekshana/Documents/visualDet3D/visualDet3D/networks/lib/PSM_cost_volume.py:55: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  volatile= not self.training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSM Cos Volume takes 0.008855819702148438 seconds at call time 1\n",
      "1\n",
      "PSM Cos Volume takes 0.01848316192626953 seconds at call time 2\n",
      "PSM Cos Volume takes 0.013000726699829102 seconds at call time 3\n",
      "Cost Volume takes 0.007517576217651367 seconds at call time 1\n",
      "2\n",
      "PSM Cos Volume takes 0.018377304077148438 seconds at call time 4\n",
      "PSM Cos Volume takes 0.011578798294067383 seconds at call time 5\n",
      "Cost Volume takes 0.01020956039428711 seconds at call time 2\n",
      "3\n",
      "PSM Cos Volume takes 0.021944761276245117 seconds at call time 6\n",
      "PSM Cos Volume takes 0.010026931762695312 seconds at call time 7\n",
      "Cost Volume takes 0.008070707321166992 seconds at call time 3\n",
      "4\n",
      "PSM Cos Volume takes 0.022031307220458984 seconds at call time 8\n",
      "PSM Cos Volume takes 0.010288000106811523 seconds at call time 9\n",
      "Cost Volume takes 0.007964611053466797 seconds at call time 4\n",
      "5\n",
      "PSM Cos Volume takes 0.023787736892700195 seconds at call time 10\n",
      "PSM Cos Volume takes 0.009984254837036133 seconds at call time 11\n",
      "Cost Volume takes 0.008086204528808594 seconds at call time 5\n",
      "6\n",
      "PSM Cos Volume takes 0.02207803726196289 seconds at call time 12\n",
      "PSM Cos Volume takes 0.00918126106262207 seconds at call time 13\n",
      "Cost Volume takes 0.008318185806274414 seconds at call time 6\n",
      "7\n",
      "PSM Cos Volume takes 0.02188897132873535 seconds at call time 14\n",
      "PSM Cos Volume takes 0.010121583938598633 seconds at call time 15\n",
      "Cost Volume takes 0.007474184036254883 seconds at call time 7\n",
      "8\n",
      "PSM Cos Volume takes 0.02185678482055664 seconds at call time 16\n",
      "PSM Cos Volume takes 0.010085821151733398 seconds at call time 17\n",
      "Cost Volume takes 0.007435321807861328 seconds at call time 8\n",
      "9\n",
      "PSM Cos Volume takes 0.022729873657226562 seconds at call time 18\n",
      "PSM Cos Volume takes 0.010865926742553711 seconds at call time 19\n",
      "Cost Volume takes 0.007402181625366211 seconds at call time 9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "bb_list=[]\n",
    "image_list=[]\n",
    "track_list_all_objects=[]\n",
    "size = 200#837\n",
    "for i in range (size):\n",
    "    print(i)\n",
    "    imagei,track_bbs_ids=assignTrackID(i)\n",
    "    bb=track_bbs_ids[-1,:-1]\n",
    "    bb_list.append(bb)\n",
    "    track_list_all_objects.append(track_bbs_ids)\n",
    "    image_list.append(imagei)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55523225",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_list_copy=bb_list.copy()\n",
    "image_list_copy=image_list.copy()\n",
    "track_list_all_objects_copy=track_list_all_objects.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89adefae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bb_list = bb_list_copy\n",
    "# image_list = image_list_copy\n",
    "# track_list_all_objects = track_list_all_objects_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f661247d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theekshana/anaconda3/envs/YOLO3D/lib/python3.7/site-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "bb_list = np.array(bb_list)\n",
    "image_list = np.array(image_list)\n",
    "track_list_all_objects = np.array(track_list_all_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3826802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 4)\n",
      "(200, 288, 1280, 3)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "print(bb_list.shape)\n",
    "print(image_list.shape)\n",
    "print(track_list_all_objects.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8138fd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save numpy array as csv file\n",
    "# # from numpy import asarray\n",
    "# # from numpy import savetxt\n",
    "# # # save to csv file\n",
    "# # savetxt('data.csv', data, delimiter=',')\n",
    "\n",
    "# dict = {'bb_list': bb_list, 'image_list': image_list, 'track_list_all_objects': track_list_all_objects}  \n",
    "       \n",
    "# df = pd.DataFrame(dict) \n",
    "    \n",
    "# # saving the dataframe \n",
    "# df.to_csv('images_with_tracking_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9adc65f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# # read the dataframe \n",
    "# df=pd.read_csv('images_with_tracking_data.csv') \n",
    "\n",
    "# bb_list=df['bb_list']\n",
    "# image_list=df['image_list']\n",
    "# track_list_all_objects=df['track_list_all_objects']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "950d05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a51b86b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01f34d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bb_list_saved=[[692.4096873 ,  83.32576469, 763.98346397, 135.0803572 ],\n",
    "#  [691.81421877,  83.6167289 , 763.05056484, 136.07131263],\n",
    "#  [691.5050883 ,  83.55840326, 762.62165936, 136.3094644 ],\n",
    "#  [691.05792471,  83.41331726, 762.25365657, 136.20346428],\n",
    "#  [690.71082536,  83.29223695, 761.77100816, 136.08748713],\n",
    "#  [690.89720186,  83.23456592, 762.05860953, 136.03581485],\n",
    "#  [690.67949149,  83.11648409, 762.01686549, 135.81260878],\n",
    "#  [690.67635627,  83.06941189, 762.27088863, 135.63069714],\n",
    "#  [690.58490485,  82.90524512, 762.18728658, 135.3615848 ],\n",
    "#  [690.55505677,  82.78152507, 762.08500008, 134.98401918],\n",
    "#  [690.67132736,  82.69352507, 762.1828055 , 134.80414822],\n",
    "#  [690.42393712,  82.8231493 , 761.88927733, 134.87368065],\n",
    "#  [690.62669307,  83.005109  , 761.85377581, 135.04213458],\n",
    "#  [690.74118848,  83.17900669, 761.74506807, 135.10095599],\n",
    "#  [690.65556984,  83.17713975, 761.52943304, 134.99402932],\n",
    "#  [690.45706986,  83.02642155, 761.06514421, 134.65676227],\n",
    "#  [690.08712869,  82.82139043, 759.92469403, 134.0765081 ],\n",
    "#  [689.87919732,  82.97912807, 758.83868433, 133.87316785],\n",
    "#  [689.66248336,  82.65531639, 757.74704639, 133.08540318],\n",
    "#  [689.69638784,  82.53336025, 756.88784659, 132.60748618],\n",
    "#  [689.33437156,  82.47360251, 755.62710964, 132.25341072],\n",
    "#  [689.05524596,  82.59750125, 754.63475047, 131.97200342],\n",
    "#  [688.79578226,  82.74657588, 753.68192723, 131.66659305],\n",
    "#  [688.67746629,  82.57713056, 753.04369616, 131.10890666],\n",
    "#  [688.16450752,  82.50804333, 752.33712441, 130.76275417],\n",
    "#  [687.91302451,  82.64346509, 751.74394857, 130.58160571],\n",
    "#  [687.25138815,  82.35028698, 750.71776515, 129.94480332],\n",
    "#  [686.65695754,  82.26836599, 749.79229301, 129.38687778],\n",
    "#  [685.56618428,  82.52246515, 748.37341794, 129.25360775],\n",
    "#  [684.82584163,  82.38370217, 746.89305958, 128.6975299 ],\n",
    "#  [683.99307131,  82.14694155, 745.12251092, 127.86330358],\n",
    "#  [683.14184441,  82.31159361, 743.51353566, 127.42897417],\n",
    "#  [683.17884157,  82.29014919, 742.82709913, 126.96363228],\n",
    "#  [682.6465723 ,  82.73561364, 741.55186618, 126.92129064],\n",
    "#  [681.82399303,  83.23288559, 739.97212111, 126.9720279 ],\n",
    "#  [681.21231321,  83.74218498, 738.41022176, 126.8774326 ],\n",
    "#  [680.87531837,  83.9875739 , 737.03089999, 126.5622305 ],\n",
    "#  [680.7207552 ,  84.34918536, 735.82259335, 126.43205274],\n",
    "#  [680.51710579,  84.5732593 , 734.75832956, 126.22311953],\n",
    "#  [680.67742428,  84.7246396 , 734.01635407, 125.90068668],\n",
    "#  [680.73272985,  84.86300609, 733.19315595, 125.49480307],\n",
    "#  [680.71273058,  85.09916893, 732.61289667, 125.24441856],\n",
    "#  [680.40374645,  85.53936385, 731.73595696, 125.18381283],\n",
    "#  [680.27209941,  85.94770252, 731.16242866, 125.20010774],\n",
    "#  [680.1702006 ,  86.07841413, 730.75015954, 124.92244777],\n",
    "#  [679.9678919 ,  86.20204695, 729.96391634, 124.6386028 ],\n",
    "#  [679.53113463,  86.28862055, 729.10950979, 124.32777588],\n",
    "#  [679.09622384,  86.66094516, 728.26776925, 124.22197444],\n",
    "#  [678.72676948,  86.48949057, 727.26433854, 123.55195741],\n",
    "#  [678.4769713 ,  86.54621289, 726.30977046, 123.20588031],\n",
    "#  [678.17251353,  86.60085388, 725.28407746, 122.86350103],\n",
    "#  [678.25688059,  86.61021641, 724.78346509, 122.5821465 ],\n",
    "#  [677.82316116,  86.86534727, 723.91081797, 122.64001013],\n",
    "#  [677.47035396,  86.97779496, 723.20542601, 122.40048365],\n",
    "#  [677.2170934 ,  87.26940807, 722.60050491, 122.44933595],\n",
    "#  [676.88228094,  87.46185291, 721.84705812, 122.24866663],\n",
    "#  [676.36074226,  87.83675604, 720.98305308, 122.28486214],\n",
    "#  [676.02086005,  87.91560317, 720.4432629 , 122.06251591],\n",
    "#  [675.80495728,  87.4741554 , 719.96029465, 121.34737008],\n",
    "#  [675.29989001,  87.09289645, 719.11149097, 120.65128009],\n",
    "#  [674.88667068,  86.99118603, 718.3551252 , 120.31920445],\n",
    "#  [674.42554747,  86.23192798, 717.57916302, 119.31614147],\n",
    "#  [673.65973774,  84.59471527, 716.41798285, 117.42190087],\n",
    "#  [673.33886157,  83.46788182, 715.64360791, 115.96966079],\n",
    "#  [673.01251465,  82.15184126, 714.81748309, 114.37534872],\n",
    "#  [673.05176346,  81.32514563, 714.6460938 , 113.29516927],\n",
    "#  [672.67358457,  81.02402516, 714.12155462, 112.76665819],\n",
    "#  [672.15963446,  80.98141946, 713.40049259, 112.44144907],\n",
    "#  [671.71044504,  81.07245387, 712.86584114, 112.24340549],\n",
    "#  [670.9499307 ,  80.7731648 , 711.99255718, 111.75560203],\n",
    "#  [670.24346848,  80.25151323, 711.08581043, 110.99955986],\n",
    "#  [669.82408886,  79.6951804 , 710.50194308, 110.2905899 ],\n",
    "#  [669.4958366 ,  79.59219779, 709.78241358, 110.0408243 ],\n",
    "#  [669.12275278,  79.30795627, 708.94149101, 109.62340761],\n",
    "#  [668.94145073,  79.04715109, 708.26015396, 109.17080081],\n",
    "#  [668.74822602,  79.01989271, 707.51478372, 108.92184631],\n",
    "#  [667.82541597,  79.40840452, 706.12084553, 108.94189043],\n",
    "#  [667.29506601,  79.69668749, 705.06545796, 108.79064991],\n",
    "#  [667.10803741,  79.72347144, 704.40943092, 108.47438253],\n",
    "#  [666.71656228,  80.33324151, 703.58505739, 108.76825419],\n",
    "#  [666.43356558,  80.9725867 , 702.73757871, 109.08053053],\n",
    "#  [666.05197417,  81.25645264, 702.08037852, 109.03626227],\n",
    "#  [665.29448705,  81.70451241, 701.27061683, 109.25019043],\n",
    "#  [664.50010782,  81.83203004, 700.37927834, 109.18670343],\n",
    "#  [664.01145407,  81.81744898, 699.63424132, 108.98709217],\n",
    "#  [663.42147915,  81.71162496, 698.88154659, 108.62926269],\n",
    "#  [662.4780403 ,  81.86543504, 697.77924615, 108.4904378 ],\n",
    "#  [661.55531243,  82.11712391, 696.40170007, 108.39704611],\n",
    "#  [660.79955387,  82.49189177, 695.10366815, 108.32959036],\n",
    "#  [660.27666771,  82.68622628, 694.06272519, 108.17358636],\n",
    "#  [659.49182559,  82.77606853, 692.7796382 , 107.88990612],\n",
    "#  [658.85271787,  82.4267966 , 691.5972877 , 107.18794515],\n",
    "#  [658.02861484,  82.227788  , 690.31866174, 106.54396447],\n",
    "#  [657.22679583,  82.26349032, 689.2412406 , 106.25415113],\n",
    "#  [656.93918638,  82.30204675, 688.39295055, 105.95609382],\n",
    "#  [656.68119852,  82.35995328, 687.59096205, 105.62719212],\n",
    "#  [655.64217074,  82.44026167, 685.95387461, 105.49531818],\n",
    "#  [654.69621588,  82.37180078, 684.25600921, 105.06641894]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b40965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ed32f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_next_predicted_trajectory(image,bb,i):\n",
    "#     bb=bb.astype(int)\n",
    "    xm=int((bb[0]+bb[2])/2)\n",
    "    ym=int((bb[1]+bb[3])/2)\n",
    "     # font\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    # org\n",
    "    org = int(xm),int(ym)\n",
    "    # fontScale\n",
    "    fontScale = 0.9\n",
    "    # Line thickness of 2 px\n",
    "    thickness = 2\n",
    "    # Blue color in BGR\n",
    "    color=(0, 255, 0)\n",
    "    text_color_bg=(0, 0, 0)\n",
    "#     text_size, _ = cv2.getTextSize(name, font, fontScale, thickness)\n",
    "#     text_w, text_h = text_size\n",
    "#     cv2.rectangle(rgb_image, (x1 , y1-10 - text_h), (x1 + text_w, y1-10), text_color_bg, -1)\n",
    "            \n",
    "    # Using cv2.putText() method\n",
    "    name=str(i)\n",
    "    cv2.putText(image,name, org, font, fontScale, color, thickness, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66444c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_danger_zone=400#300#400\n",
    "x1_danger_zone=800#900#800\n",
    "y0_danger_zone=300\n",
    "y1_danger_zone=200#150#200\n",
    "w_danger_zone=100#150#100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d00ae85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_danger_zone(rgb_image):\n",
    "    x0=x0_danger_zone\n",
    "    x1=x1_danger_zone\n",
    "    y0=y0_danger_zone\n",
    "    y1=y1_danger_zone\n",
    "    w=w_danger_zone\n",
    "    thickness=3\n",
    "    color=text_color_bg=(0, 125, 255)\n",
    "    pts=np.array([[x0,y0],[x0+w,y1],[x1-w,y1],[x1,y0]],np.int32)\n",
    "    isClosed=True\n",
    "    cv2.polylines(rgb_image, [pts],isClosed, color, thickness)\n",
    "#     cv2.rectangle(rgb_image, (x0 , y0), (x1, y1), text_color_bg, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b68b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.imsave('trajectory.png')\n",
    "# fig = plt.figure(figsize=(16,9))\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53ff6d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(16,9))\n",
    "# image_zone=image.copy()\n",
    "# draw_danger_zone(image_zone)\n",
    "# plt.imshow(image_zone)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4bbb0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imwrite(\"danger_zone.png\",cv2.cvtColor(image_zone, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4920bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=1\n",
    "# for image in image_list.copy():\n",
    "#     fig = plt.figure(figsize=(16,9))\n",
    "#     clear_output(wait=True)\n",
    "#     draw_danger_zone(image)\n",
    "#     plt.imshow(image)\n",
    "#     plt.xlabel(i)\n",
    "# #     cv2.imwrite(\"data/danger_zone %03d.png\"%i,cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "#     i+=1\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc86d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_list=track_list_all_objects.copy()\n",
    "bb_list_c=bb_list.copy()\n",
    "image_list_c=image_list.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6e2db821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_in_zone(x,y):\n",
    "    if x0<x<x1 and y0>y>y1:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb57be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zone_check_point(bb):\n",
    "    x0,y0,x1,y1=bb\n",
    "    if x0<x1_danger_zone:\n",
    "        x=x0\n",
    "    else:\n",
    "        x=x1\n",
    "    y=max(y0,y1)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "777f2cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_zone_check_point(track_list[0][-1][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e405ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find current vehicles in danger zone\n",
    "x0=x0_danger_zone #400\n",
    "x1=x1_danger_zone #800\n",
    "y0=y0_danger_zone #300\n",
    "y1=y1_danger_zone #200\n",
    "w=w_danger_zone #100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e9ac1b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame 0\n",
      "frame 1\n",
      "frame 2\n",
      "frame 3\n",
      "frame 4\n",
      "frame 5\n",
      "frame 6\n",
      "frame 7\n",
      "frame 8\n",
      "frame 9\n",
      "frame 10\n",
      "frame 11\n",
      "frame 12\n",
      "frame 13\n",
      "frame 14\n",
      "frame 15\n",
      "frame 16\n",
      "frame 17\n",
      "frame 18\n",
      "frame 19\n",
      "frame 20\n",
      "frame 21\n",
      "frame 22\n",
      "frame 23\n",
      "frame 24\n",
      "frame 25\n",
      "frame 26\n",
      "frame 27\n",
      "frame 28\n",
      "frame 29\n",
      "frame 30\n",
      "frame 31\n",
      "frame 32\n",
      "frame 33\n",
      "frame 34\n",
      "frame 35\n",
      "frame 36\n",
      "frame 37\n",
      "frame 38\n",
      "frame 39\n",
      "frame 40\n",
      "frame 41\n",
      "frame 42\n",
      "frame 43\n",
      "frame 44\n",
      "frame 45\n",
      "frame 46\n",
      "frame 47\n",
      "frame 48\n",
      "frame 49\n",
      "frame 50\n",
      "frame 51\n",
      "frame 52\n",
      "frame 53\n",
      "frame 54\n",
      "frame 55\n",
      "frame 56\n",
      "frame 57\n",
      "frame 58\n",
      "frame 59\n",
      "frame 60\n",
      "frame 61\n",
      "frame 62\n",
      "frame 63\n",
      "frame 64\n",
      "frame 65\n",
      "frame 66\n",
      "frame 67\n",
      "frame 68\n",
      "frame 69\n",
      "frame 70\n",
      "frame 71\n",
      "frame 72\n",
      "frame 73\n",
      "frame 74\n",
      "frame 75\n",
      "frame 76\n",
      "frame 77\n",
      "frame 78\n",
      "frame 79\n",
      "frame 80\n",
      "frame 81\n",
      "frame 82\n",
      "frame 83\n",
      "frame 84\n",
      "frame 85\n",
      "frame 86\n",
      "frame 87\n",
      "frame 88\n",
      "frame 89\n",
      "frame 90\n",
      "frame 91\n",
      "frame 92\n",
      "frame 93\n",
      "frame 94\n",
      "frame 95\n",
      "frame 96\n",
      "frame 97\n",
      "frame 98\n",
      "frame 99\n",
      "frame 100\n",
      "frame 101\n",
      "frame 102\n",
      "frame 103\n",
      "frame 104\n",
      "frame 105\n",
      "frame 106\n",
      "frame 107\n",
      "frame 108\n",
      "frame 109\n",
      "frame 110\n",
      "frame 111\n",
      "frame 112\n",
      "frame 113\n",
      "frame 114\n",
      "frame 115\n",
      "frame 116\n",
      "frame 117\n",
      "frame 118\n",
      "frame 119\n",
      "frame 120\n",
      "frame 121\n",
      "frame 122\n",
      "frame 123\n",
      "frame 124\n",
      "frame 125\n",
      "frame 126\n",
      "frame 127\n",
      "frame 128\n",
      "frame 129\n",
      "frame 130\n",
      "frame 131\n",
      "frame 132\n",
      "frame 133\n",
      "frame 134\n",
      "frame 135\n",
      "frame 136\n",
      "frame 137\n",
      "frame 138\n",
      "frame 139\n",
      "frame 140\n",
      "frame 141\n",
      "frame 142\n",
      "frame 143\n",
      "frame 144\n",
      "frame 145\n",
      "frame 146\n",
      "frame 147\n",
      "frame 148\n",
      "frame 149\n",
      "frame 150\n",
      "frame 151\n",
      "frame 152\n",
      "frame 153\n",
      "frame 154\n",
      "frame 155\n",
      "frame 156\n",
      "frame 157\n",
      "frame 158\n",
      "frame 159\n",
      "frame 160\n",
      "frame 161\n",
      "frame 162\n",
      "frame 163\n",
      "Warning! Frame: 163 vehicle ID: 33\n",
      "frame 164\n",
      "Warning! Frame: 164 vehicle ID: 33\n",
      "frame 165\n",
      "Warning! Frame: 165 vehicle ID: 33\n",
      "frame 166\n",
      "Warning! Frame: 166 vehicle ID: 33\n",
      "frame 167\n",
      "Warning! Frame: 167 vehicle ID: 33\n",
      "frame 168\n",
      "Warning! Frame: 168 vehicle ID: 33\n",
      "frame 169\n",
      "Warning! Frame: 169 vehicle ID: 33\n",
      "frame 170\n",
      "Warning! Frame: 170 vehicle ID: 33\n",
      "frame 171\n",
      "frame 172\n",
      "frame 173\n",
      "frame 174\n",
      "frame 175\n",
      "frame 176\n",
      "frame 177\n",
      "frame 178\n",
      "frame 179\n",
      "frame 180\n",
      "frame 181\n",
      "frame 182\n",
      "frame 183\n",
      "frame 184\n",
      "frame 185\n",
      "frame 186\n",
      "frame 187\n",
      "frame 188\n",
      "frame 189\n",
      "frame 190\n",
      "frame 191\n",
      "frame 192\n",
      "frame 193\n",
      "frame 194\n",
      "frame 195\n",
      "frame 196\n",
      "frame 197\n",
      "frame 198\n",
      "frame 199\n"
     ]
    }
   ],
   "source": [
    "for frame,track in enumerate(track_list):\n",
    "    print('frame',frame)\n",
    "    for vehicle in track:\n",
    "        i=int(vehicle[-1])\n",
    "        bb=vehicle[:-1]\n",
    "        x,y=get_zone_check_point(bb)\n",
    "        if is_in_zone(x,y):\n",
    "            print('Warning!','Frame:',frame,'vehicle ID:',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a2763eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_zone_warning(image_c,id_list):\n",
    "#     fig = plt.figure(figsize=(16,9))\n",
    "#     clear_output(wait=True)\n",
    "#     draw_danger_zone(image_c)\n",
    "\n",
    "    message= \"Warning! ID:\"+ str(id_list)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    org = 480,30\n",
    "    fontScale = 1\n",
    "    thickness = 1\n",
    "    color=(255,0,0)\n",
    "\n",
    "    cv2.putText(image_c,message, org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "#     plt.imshow(image_c)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b272022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no=588\n",
    "# ind=44\n",
    "# image_check=image_list_c[no].copy()\n",
    "# draw_danger_zone(image_check)\n",
    "# show_zone_warning(image_check,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d27b183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame 0\n",
      "frame 1\n",
      "frame 2\n",
      "frame 3\n",
      "frame 4\n",
      "frame 5\n",
      "frame 6\n",
      "frame 7\n",
      "frame 8\n",
      "frame 9\n",
      "frame 10\n",
      "frame 11\n",
      "frame 12\n",
      "frame 13\n",
      "frame 14\n",
      "frame 15\n",
      "frame 16\n",
      "frame 17\n",
      "frame 18\n",
      "frame 19\n",
      "frame 20\n",
      "frame 21\n",
      "frame 22\n",
      "frame 23\n",
      "frame 24\n",
      "frame 25\n",
      "frame 26\n",
      "frame 27\n",
      "frame 28\n",
      "frame 29\n",
      "frame 30\n",
      "frame 31\n",
      "frame 32\n",
      "frame 33\n",
      "frame 34\n",
      "frame 35\n",
      "frame 36\n",
      "frame 37\n",
      "frame 38\n",
      "frame 39\n",
      "frame 40\n",
      "frame 41\n",
      "frame 42\n",
      "frame 43\n",
      "frame 44\n",
      "frame 45\n",
      "frame 46\n",
      "frame 47\n",
      "frame 48\n",
      "frame 49\n",
      "frame 50\n",
      "frame 51\n",
      "frame 52\n",
      "frame 53\n",
      "frame 54\n",
      "frame 55\n",
      "frame 56\n",
      "frame 57\n",
      "frame 58\n",
      "frame 59\n",
      "frame 60\n",
      "frame 61\n",
      "frame 62\n",
      "frame 63\n",
      "frame 64\n",
      "frame 65\n",
      "frame 66\n",
      "frame 67\n",
      "frame 68\n",
      "frame 69\n",
      "frame 70\n",
      "frame 71\n",
      "frame 72\n",
      "frame 73\n",
      "frame 74\n",
      "frame 75\n",
      "frame 76\n",
      "frame 77\n",
      "frame 78\n",
      "frame 79\n",
      "frame 80\n",
      "frame 81\n",
      "frame 82\n",
      "frame 83\n",
      "frame 84\n",
      "frame 85\n",
      "frame 86\n",
      "frame 87\n",
      "frame 88\n",
      "frame 89\n",
      "frame 90\n",
      "frame 91\n",
      "frame 92\n",
      "frame 93\n",
      "frame 94\n",
      "frame 95\n",
      "frame 96\n",
      "frame 97\n",
      "frame 98\n",
      "frame 99\n",
      "frame 100\n",
      "frame 101\n",
      "frame 102\n",
      "frame 103\n",
      "frame 104\n",
      "frame 105\n",
      "frame 106\n",
      "frame 107\n",
      "frame 108\n",
      "frame 109\n",
      "frame 110\n",
      "frame 111\n",
      "frame 112\n",
      "frame 113\n",
      "frame 114\n",
      "frame 115\n",
      "frame 116\n",
      "frame 117\n",
      "frame 118\n",
      "frame 119\n",
      "frame 120\n",
      "frame 121\n",
      "frame 122\n",
      "frame 123\n",
      "frame 124\n",
      "frame 125\n",
      "frame 126\n",
      "frame 127\n",
      "frame 128\n",
      "frame 129\n",
      "frame 130\n",
      "frame 131\n",
      "frame 132\n",
      "frame 133\n",
      "frame 134\n",
      "frame 135\n",
      "frame 136\n",
      "frame 137\n",
      "frame 138\n",
      "frame 139\n",
      "frame 140\n",
      "frame 141\n",
      "frame 142\n",
      "frame 143\n",
      "frame 144\n",
      "frame 145\n",
      "frame 146\n",
      "frame 147\n",
      "frame 148\n",
      "frame 149\n",
      "frame 150\n",
      "frame 151\n",
      "frame 152\n",
      "frame 153\n",
      "frame 154\n",
      "frame 155\n",
      "frame 156\n",
      "frame 157\n",
      "frame 158\n",
      "frame 159\n",
      "frame 160\n",
      "frame 161\n",
      "frame 162\n",
      "frame 163\n",
      "Warning! Frame: 163 vehicle ID: 33\n",
      "frame 164\n",
      "Warning! Frame: 164 vehicle ID: 33\n",
      "frame 165\n",
      "Warning! Frame: 165 vehicle ID: 33\n",
      "frame 166\n",
      "Warning! Frame: 166 vehicle ID: 33\n",
      "frame 167\n",
      "Warning! Frame: 167 vehicle ID: 33\n",
      "frame 168\n",
      "Warning! Frame: 168 vehicle ID: 33\n",
      "frame 169\n",
      "Warning! Frame: 169 vehicle ID: 33\n",
      "frame 170\n",
      "Warning! Frame: 170 vehicle ID: 33\n",
      "frame 171\n",
      "frame 172\n",
      "frame 173\n",
      "frame 174\n",
      "frame 175\n",
      "frame 176\n",
      "frame 177\n",
      "frame 178\n",
      "frame 179\n",
      "frame 180\n",
      "frame 181\n",
      "frame 182\n",
      "frame 183\n",
      "frame 184\n",
      "frame 185\n",
      "frame 186\n",
      "frame 187\n",
      "frame 188\n",
      "frame 189\n",
      "frame 190\n",
      "frame 191\n",
      "frame 192\n",
      "frame 193\n",
      "frame 194\n",
      "frame 195\n",
      "frame 196\n",
      "frame 197\n",
      "frame 198\n",
      "frame 199\n"
     ]
    }
   ],
   "source": [
    "for frame,track in enumerate(track_list):\n",
    "    id_list=[]\n",
    "    print('frame',frame)\n",
    "    for vehicle in track:\n",
    "        vehicle_ID=int(vehicle[-1])\n",
    "        bb=vehicle[:-1]\n",
    "        x,y=get_zone_check_point(bb)\n",
    "        if is_in_zone(x,y):\n",
    "            print('Warning!','Frame:',frame,'vehicle ID:',vehicle_ID)\n",
    "            id_list.append(vehicle_ID)\n",
    "            \n",
    "    image=image_list_c[frame].copy()\n",
    "    draw_danger_zone(image)\n",
    "    if len(id_list)>0:\n",
    "        show_zone_warning(image,id_list)\n",
    "#     cv2.imwrite(\"data/collision_warning %03d.png\"%frame,cv2.cvtColor(image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f7b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for track in track_list[0]:\n",
    "#     i=int(track[-1])\n",
    "#     bb=track[:-1]\n",
    "#     print(i,bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c673bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## warning for current vehicles in danger zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5faeeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(track_list[0][0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87e82ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "frame 0\n",
      "7 6 5 4 3 2 1 \n",
      "frame 1\n",
      "7 6 5 4 3 2 1 \n",
      "frame 2\n",
      "8 7 6 5 4 3 2 1 \n",
      "frame 3\n",
      "7 6 5 4 3 2 1 \n",
      "frame 4\n",
      "7 6 5 4 3 2 1 \n",
      "frame 5\n",
      "8 7 6 5 4 3 2 1 \n",
      "frame 6\n",
      "8 7 6 5 4 3 2 1 \n",
      "frame 7\n",
      "8 7 6 5 4 3 2 1 \n",
      "frame 8\n",
      "8 7 6 5 4 3 2 1 \n",
      "frame 9\n",
      "8 7 6 5 4 3 2 1 \n",
      "frame 10\n",
      "8 7 6 5 4 3 2 1 \n",
      "frame 11\n",
      "9 8 7 6 5 3 2 1 \n",
      "frame 12\n",
      "9 8 7 6 5 3 2 1 \n",
      "frame 13\n",
      "10 9 8 7 6 5 3 2 1 \n",
      "frame 14\n",
      "10 9 8 7 6 5 3 2 1 \n",
      "frame 15\n",
      "10 9 8 7 6 5 3 2 1 \n",
      "frame 16\n",
      "10 9 8 7 6 5 3 2 1 \n",
      "frame 17\n",
      "10 9 8 6 5 3 2 1 \n",
      "frame 18\n",
      "10 9 8 6 5 3 2 1 \n",
      "frame 19\n",
      "10 9 8 6 5 3 2 1 \n",
      "frame 20\n",
      "10 9 8 6 5 3 2 1 \n",
      "frame 21\n",
      "11 10 9 8 6 5 3 2 1 \n",
      "frame 22\n",
      "11 10 9 8 6 5 3 2 1 \n",
      "frame 23\n",
      "11 10 9 8 6 5 3 2 1 \n",
      "frame 24\n",
      "11 10 9 8 6 5 3 2 1 \n",
      "frame 25\n",
      "11 10 9 8 6 5 3 2 1 \n",
      "frame 26\n",
      "11 10 9 8 6 5 3 2 1 \n",
      "frame 27\n",
      "11 10 8 6 5 3 2 1 \n",
      "frame 28\n",
      "11 10 8 6 5 3 2 1 \n",
      "frame 29\n",
      "11 10 8 6 5 3 2 1 \n",
      "frame 30\n",
      "11 10 8 6 5 3 2 1 \n",
      "frame 31\n",
      "11 10 8 6 5 3 2 1 \n",
      "frame 32\n",
      "12 11 10 8 6 5 3 2 1 \n",
      "frame 33\n",
      "12 11 10 8 6 5 3 2 1 \n",
      "frame 34\n",
      "12 11 10 8 6 5 3 2 1 \n",
      "frame 35\n",
      "12 11 10 8 6 5 3 2 1 \n",
      "frame 36\n",
      "12 11 10 8 6 5 3 2 1 \n",
      "frame 37\n",
      "13 12 11 10 8 6 5 3 2 1 \n",
      "frame 38\n",
      "13 12 11 10 8 6 5 3 2 1 \n",
      "frame 39\n",
      "13 12 11 10 8 6 5 3 2 1 \n",
      "frame 40\n",
      "13 12 11 10 8 6 5 3 2 1 \n",
      "frame 41\n",
      "13 12 11 10 8 6 5 3 2 1 \n",
      "frame 42\n",
      "13 12 11 10 8 6 5 3 2 1 \n",
      "frame 43\n",
      "13 12 11 10 8 6 5 3 2 1 \n",
      "frame 44\n",
      "13 12 11 8 6 5 3 2 1 \n",
      "frame 45\n",
      "13 12 11 8 6 5 3 2 1 \n",
      "frame 46\n",
      "13 12 11 8 6 5 3 2 1 \n",
      "frame 47\n",
      "13 12 11 8 6 5 3 2 1 \n",
      "frame 48\n",
      "14 12 11 8 6 5 3 2 1 \n",
      "frame 49\n",
      "14 12 11 8 6 5 3 2 1 \n",
      "frame 50\n",
      "14 12 11 8 6 5 3 2 1 \n",
      "frame 51\n",
      "14 12 11 8 6 5 3 2 1 \n",
      "frame 52\n",
      "14 12 11 8 5 3 2 1 \n",
      "frame 53\n",
      "14 12 11 8 5 3 2 1 \n",
      "frame 54\n",
      "14 12 11 8 5 3 2 1 \n",
      "frame 55\n",
      "14 12 11 8 3 2 1 \n",
      "frame 56\n",
      "14 12 11 8 3 2 1 \n",
      "frame 57\n",
      "14 12 11 8 3 2 1 \n",
      "frame 58\n",
      "14 12 11 8 3 2 1 \n",
      "frame 59\n",
      "14 12 11 8 3 2 1 \n",
      "frame 60\n",
      "14 11 8 3 2 1 \n",
      "frame 61\n",
      "14 11 8 3 2 1 \n",
      "frame 62\n",
      "14 11 8 3 2 1 \n",
      "frame 63\n",
      "14 11 8 3 2 1 \n",
      "frame 64\n",
      "15 14 11 8 3 2 1 \n",
      "frame 65\n",
      "16 15 14 11 8 3 2 1 \n",
      "frame 66\n",
      "16 15 14 11 8 3 2 1 \n",
      "frame 67\n",
      "16 15 11 8 3 2 \n",
      "frame 68\n",
      "16 15 11 8 3 2 \n",
      "frame 69\n",
      "16 15 11 8 3 2 \n",
      "frame 70\n",
      "16 15 11 8 3 2 \n",
      "frame 71\n",
      "16 15 11 8 3 2 \n",
      "frame 72\n",
      "18 16 15 11 8 3 2 \n",
      "frame 73\n",
      "19 18 16 15 11 8 3 2 \n",
      "frame 74\n",
      "19 18 16 15 11 8 3 2 \n",
      "frame 75\n",
      "19 18 16 15 11 8 3 2 \n",
      "frame 76\n",
      "19 18 16 15 11 8 3 2 \n",
      "frame 77\n",
      "19 18 16 15 11 8 3 2 \n",
      "frame 78\n",
      "19 18 16 15 11 8 3 2 \n",
      "frame 79\n",
      "19 18 16 15 11 8 3 2 \n",
      "frame 80\n",
      "19 18 16 15 11 8 3 2 \n",
      "frame 81\n",
      "19 18 16 15 11 8 3 2 \n",
      "frame 82\n",
      "19 18 16 15 11 8 3 2 \n",
      "frame 83\n",
      "22 19 18 16 15 11 8 3 2 \n",
      "frame 84\n",
      "22 19 18 16 15 11 8 3 2 \n",
      "frame 85\n",
      "22 19 18 16 11 8 3 2 \n",
      "frame 86\n",
      "19 18 16 11 8 3 2 \n",
      "frame 87\n",
      "19 18 16 11 8 3 2 \n",
      "frame 88\n",
      "19 18 16 11 8 3 2 \n",
      "frame 89\n",
      "19 18 16 11 8 3 2 \n",
      "frame 90\n",
      "19 18 16 11 8 3 2 \n",
      "frame 91\n",
      "19 18 16 11 8 3 2 \n",
      "frame 92\n",
      "19 18 16 11 8 3 2 \n",
      "frame 93\n",
      "24 19 18 16 11 8 3 2 \n",
      "frame 94\n",
      "24 19 18 16 11 8 2 \n",
      "frame 95\n",
      "24 19 18 16 11 8 2 \n",
      "frame 96\n",
      "24 19 18 16 11 8 2 \n",
      "frame 97\n",
      "24 19 18 16 11 8 2 \n",
      "frame 98\n",
      "24 19 18 16 11 8 2 \n",
      "frame 99\n",
      "24 19 18 16 11 8 2 \n",
      "frame 100\n",
      "24 19 18 16 11 8 2 \n",
      "frame 101\n",
      "19 18 16 11 8 2 \n",
      "frame 102\n",
      "28 27 19 18 16 11 8 2 \n",
      "frame 103\n",
      "28 27 19 18 16 11 8 2 \n",
      "frame 104\n",
      "28 27 19 18 16 11 8 2 \n",
      "frame 105\n",
      "28 27 19 18 16 11 8 2 \n",
      "frame 106\n",
      "29 28 19 18 16 11 8 2 \n",
      "frame 107\n",
      "29 28 19 18 16 11 8 2 \n",
      "frame 108\n",
      "29 28 19 18 16 11 8 2 \n",
      "frame 109\n",
      "29 28 19 18 16 11 8 2 \n",
      "frame 110\n",
      "29 28 19 18 16 11 8 2 \n",
      "frame 111\n",
      "29 28 19 18 16 11 8 2 \n",
      "frame 112\n",
      "29 28 19 18 16 11 8 2 \n",
      "frame 113\n",
      "29 28 19 18 16 11 8 2 \n",
      "frame 114\n",
      "29 28 19 18 16 11 8 2 \n",
      "frame 115\n",
      "29 28 19 18 16 11 8 2 \n",
      "frame 116\n",
      "29 28 19 18 16 11 8 2 \n",
      "frame 117\n",
      "29 28 19 18 16 8 2 \n",
      "frame 118\n",
      "29 28 19 18 16 8 2 \n",
      "frame 119\n",
      "29 28 19 18 16 8 2 \n",
      "frame 120\n",
      "29 28 19 18 16 8 2 \n",
      "frame 121\n",
      "29 28 19 18 16 8 2 \n",
      "frame 122\n",
      "29 28 19 18 16 8 2 \n",
      "frame 123\n",
      "29 28 19 18 16 8 2 \n",
      "frame 124\n",
      "29 28 19 18 16 8 2 \n",
      "frame 125\n",
      "29 28 19 18 16 8 2 \n",
      "frame 126\n",
      "29 28 19 18 16 8 2 \n",
      "frame 127\n",
      "29 28 19 18 16 8 2 \n",
      "frame 128\n",
      "29 28 19 18 16 8 2 \n",
      "frame 129\n",
      "29 28 19 18 16 8 2 \n",
      "frame 130\n",
      "29 28 19 18 16 8 2 \n",
      "frame 131\n",
      "29 28 19 18 16 2 \n",
      "frame 132\n",
      "29 28 19 18 16 2 \n",
      "frame 133\n",
      "29 28 19 18 16 2 \n",
      "frame 134\n",
      "29 28 19 18 16 2 \n",
      "frame 135\n",
      "29 28 19 18 16 2 \n",
      "frame 136\n",
      "29 28 19 18 16 2 \n",
      "frame 137\n",
      "29 28 19 18 16 2 \n",
      "frame 138\n",
      "29 28 19 18 16 2 \n",
      "frame 139\n",
      "29 28 19 18 16 2 \n",
      "frame 140\n",
      "29 28 19 18 16 2 \n",
      "frame 141\n",
      "29 28 19 18 16 2 \n",
      "frame 142\n",
      "29 28 19 18 16 2 \n",
      "frame 143\n",
      "31 29 28 19 18 16 2 \n",
      "frame 144\n",
      "31 29 28 19 18 16 2 \n",
      "frame 145\n",
      "31 29 28 19 18 16 2 \n",
      "frame 146\n",
      "29 28 19 18 16 2 \n",
      "frame 147\n",
      "29 28 19 18 16 2 \n",
      "frame 148\n",
      "29 28 19 18 16 2 \n",
      "frame 149\n",
      "29 28 19 18 16 2 \n",
      "frame 150\n",
      "29 28 19 18 16 2 \n",
      "frame 151\n",
      "32 29 28 19 18 16 2 \n",
      "frame 152\n",
      "32 29 28 19 18 16 2 \n",
      "frame 153\n",
      "32 29 28 19 18 16 2 \n",
      "frame 154\n",
      "32 29 28 19 18 16 2 \n",
      "frame 155\n",
      "29 28 19 18 16 2 \n",
      "frame 156\n",
      "29 28 19 18 16 2 \n",
      "frame 157\n",
      "33 29 28 19 18 16 2 \n",
      "frame 158\n",
      "33 29 28 19 18 16 2 \n",
      "frame 159\n",
      "33 29 28 19 18 16 \n",
      "frame 160\n",
      "33 29 28 19 18 16 \n",
      "frame 161\n",
      "33 29 28 19 18 16 \n",
      "frame 162\n",
      "33 29 28 19 18 16 \n",
      "frame 163\n",
      "33 28 19 18 16 \n",
      "frame 164\n",
      "33 28 19 18 16 \n",
      "frame 165\n",
      "33 28 19 18 16 \n",
      "frame 166\n",
      "33 28 19 18 16 \n",
      "frame 167\n",
      "33 28 19 18 16 \n",
      "frame 168\n",
      "33 28 19 18 16 \n",
      "frame 169\n",
      "39 33 28 19 18 16 \n",
      "frame 170\n",
      "39 33 28 19 18 16 \n",
      "frame 171\n",
      "39 33 28 19 18 16 \n",
      "frame 172\n",
      "39 33 28 19 18 16 \n",
      "frame 173\n",
      "39 33 28 19 18 16 \n",
      "frame 174\n",
      "39 33 28 19 18 16 \n",
      "frame 175\n",
      "39 33 28 18 16 \n",
      "frame 176\n",
      "42 39 33 28 18 16 \n",
      "frame 177\n",
      "42 39 33 28 18 16 \n",
      "frame 178\n",
      "42 39 28 18 16 \n",
      "frame 179\n",
      "42 39 28 18 16 \n",
      "frame 180\n",
      "42 39 28 18 16 \n",
      "frame 181\n",
      "43 42 39 28 18 16 \n",
      "frame 182\n",
      "43 42 39 28 18 16 \n",
      "frame 183\n",
      "43 42 39 28 18 16 \n",
      "frame 184\n",
      "44 43 42 39 28 18 16 \n",
      "frame 185\n",
      "43 42 39 28 18 16 \n",
      "frame 186\n",
      "43 42 39 28 16 \n",
      "frame 187\n",
      "43 42 39 28 16 \n",
      "frame 188\n",
      "44 43 42 39 28 16 \n",
      "frame 189\n",
      "44 43 42 39 28 16 \n",
      "frame 190\n",
      "45 44 43 42 39 28 16 \n",
      "frame 191\n",
      "45 43 42 39 28 16 \n",
      "frame 192\n",
      "46 45 43 42 39 28 16 \n",
      "frame 193\n",
      "46 45 43 42 39 28 16 \n",
      "frame 194\n",
      "46 45 43 42 39 16 \n",
      "frame 195\n",
      "46 45 43 42 39 16 \n",
      "frame 196\n",
      "46 45 43 42 39 16 \n",
      "frame 197\n",
      "46 45 43 42 39 16 \n",
      "frame 198\n",
      "46 45 43 42 39 16 \n",
      "frame 199\n",
      "46 45 43 42 39 16 "
     ]
    }
   ],
   "source": [
    "# track_list[0][0][-1]       vehicle id format\n",
    "for frame,track_frame in enumerate(track_list):\n",
    "    id_list=[]\n",
    "    print('\\nframe',frame)\n",
    "    for vehicle in track_frame:\n",
    "        vehicle_ID=int(vehicle[-1])\n",
    "        print(vehicle_ID,end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4eb52abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.ion()\n",
    "#to show inside notebook \n",
    "%matplotlib inline \n",
    "for frame,track_frame in enumerate(track_list):\n",
    "    id_list=[]\n",
    "    print('frame',frame)\n",
    "    for vehicle in track_frame:\n",
    "        vehicle_ID=int(vehicle[-1])\n",
    "        bb=vehicle[:-1]\n",
    "        x,y=get_zone_check_point(bb)\n",
    "        if is_in_zone(x,y):\n",
    "            id_list.append(vehicle_ID)\n",
    "            print('Warning!','Frame:',frame,'vehicle ID:',id_list)\n",
    "            \n",
    "\n",
    "        image=image_list_c[frame].copy()\n",
    "        draw_danger_zone(image)\n",
    "    if len(id_list)>0:\n",
    "#         clear_output(wait=True) #to show in same window \n",
    "#             plt.close()\n",
    "#         show_zone_warning(image,id_list)\n",
    "#         fig = plt.figure(figsize=(16,9))\n",
    "#         plt.imshow(image)\n",
    "#         plt.show()\n",
    "            \n",
    "#     cv2.imwrite(\"data/collision_warning %03d.png\"%frame,cv2.cvtColor(image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a12c1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find current vehicles in danger zone\n",
    "x0=200\n",
    "x1=1000\n",
    "y0=300\n",
    "y1=100\n",
    "w=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee22530",
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict trajectory of vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "149da5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanBoxTrajectory(object):\n",
    "  \"\"\"\n",
    "  This class represents the internal state of individual tracked objects observed as bbox.\n",
    "  \"\"\"\n",
    "  count = 0\n",
    "  def __init__(self,bbox):\n",
    "    \"\"\"\n",
    "    Initialises a tracker using initial bounding box.\n",
    "    \"\"\"\n",
    "    #define constant velocity model\n",
    "    self.kf = KalmanFilter(dim_x=7, dim_z=4) \n",
    "    self.kf.F = np.array([[1,0,0,0,1,0,0],[0,1,0,0,0,1,0],[0,0,1,0,0,0,1],[0,0,0,1,0,0,0],  [0,0,0,0,1,0,0],[0,0,0,0,0,1,0],[0,0,0,0,0,0,1]])\n",
    "    self.kf.H = np.array([[1,0,0,0,0,0,0],[0,1,0,0,0,0,0],[0,0,1,0,0,0,0],[0,0,0,1,0,0,0]])\n",
    "\n",
    "    self.kf.R[2:,2:] *= 10.\n",
    "    self.kf.P[4:,4:] *= 1000. #give high uncertainty to the unobservable initial velocities\n",
    "    self.kf.P *= 10.\n",
    "    self.kf.Q[-1,-1] *= 0.01\n",
    "    self.kf.Q[4:,4:] *= 0.01\n",
    "\n",
    "    self.kf.x[:4] = convert_bbox_to_z(bbox)\n",
    "    self.id = KalmanBoxTrajectory.count\n",
    "    KalmanBoxTrajectory.count += 1\n",
    "    self.history = []\n",
    "\n",
    "  def update(self,bbox):\n",
    "    \"\"\"\n",
    "    Updates the state vector with observed bbox.\n",
    "    \"\"\"\n",
    "    self.history = []\n",
    "    self.kf.update(convert_bbox_to_z(bbox))    \n",
    "\n",
    "  def predict(self):\n",
    "    \"\"\"\n",
    "    Advances the state vector and returns the predicted bounding box estimate.\n",
    "    \"\"\"\n",
    "    if((self.kf.x[6]+self.kf.x[2])<=0):\n",
    "      self.kf.x[6] *= 0.0\n",
    "    self.kf.predict()\n",
    "    self.history.append(convert_x_to_bbox(self.kf.x))\n",
    "    return self.history[-1]\n",
    "\n",
    "  def get_state(self):\n",
    "    \"\"\"\n",
    "    Returns the current bounding box estimate.\n",
    "    \"\"\"\n",
    "    return convert_x_to_bbox(self.kf.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22a3dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find trajectory of vehicles in danger zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f51f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## warning for trajectory of vehicles in danger zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a87a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict future positions if past position limit {no_of_past_frames} is reached\n",
    "def \n",
    "f = KalmanBoxTracker([0,1,2,3])\n",
    "# fc = KalmanBoxTracker(f.history[-1][0])\n",
    "true=[]\n",
    "predicted_All=[]\n",
    "predicted = collections.deque(maxlen=no_of_past_frames)\n",
    "future_bb = []\n",
    "\n",
    "for i in range(1,16):\n",
    "    \n",
    "    z = [i, i+1, i+2, i+3]\n",
    "    true.append(z)\n",
    "    p = f.predict()[0]\n",
    "    f.update(z)\n",
    "    predicted.append(p[:2])\n",
    "    predicted_All.append(p[:2])\n",
    "    print('\\nlen update_history ', len(f.update_history))\n",
    "    print('hits counter ', f.hits, ' hit_streak ',f.hit_streak,' age ',f.age)\n",
    "    print('predicted :\\n', p)\n",
    "    print('Measured : ', z)\n",
    "    plt.plot(z[0],z[1], c='yellow', marker='o', markersize=12)\n",
    "    plt.plot(p[0],p[1], c='red', marker='*', markersize=9)\n",
    "    \n",
    "    if  len(f.update_history)>=no_of_past_frames :\n",
    "        print('\\n--------- %s predicted future_frames: ---------\\n'%i)\n",
    "        fc = KalmanBoxTrajectory(f.update_history[0])\n",
    "        \n",
    "        for j in range(1,no_of_past_frames):\n",
    "            fc.predict()\n",
    "            p = fc.update(f.update_history[j])\n",
    "            \n",
    "        for k in range(no_of_future_frames):\n",
    "            p = fc.predict()[0]\n",
    "            f.predict_history.append(p)\n",
    "            plt.plot(p[0],p[1], c='green', marker='o', markersize=18)\n",
    "            print('predicted future_frames:\\n', p)\n",
    "        print('\\n---------  predict_history: ---------\\n',f.predict_history)\n",
    "        print('\\n--------- %s end of predicted future_frames: ---------\\n'%i)\n",
    "            \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb324d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.ion()\n",
    "#to show inside notebook \n",
    "%matplotlib inline \n",
    "for frame,track_frame in enumerate(track_list):\n",
    "    id_list=[]\n",
    "    print('frame',frame)\n",
    "    for vehicle in track_frame:\n",
    "        vehicle_ID=int(vehicle[-1])\n",
    "        bb=vehicle[:-1]\n",
    "        x,y=get_zone_check_point(bb)\n",
    "        if is_in_zone(x,y):\n",
    "            id_list.append(vehicle_ID)\n",
    "            print('Warning!','Frame:',frame,'vehicle ID:',id_list)\n",
    "            \n",
    "\n",
    "        image=image_list_c[frame].copy()\n",
    "        draw_danger_zone(image)\n",
    "    if len(id_list)>0:\n",
    "#         clear_output(wait=True) #to show in same window \n",
    "#             plt.close()\n",
    "        show_zone_warning(image,id_list)\n",
    "        fig = plt.figure(figsize=(16,9))\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "            \n",
    "#     cv2.imwrite(\"data/collision_warning %03d.png\"%frame,cv2.cvtColor(image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4404a5",
   "metadata": {},
   "source": [
    "## 03 saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2824aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_frame_rate():\n",
    "    # Start time\n",
    "    start = time.time()\n",
    "\n",
    "    # Grab a few frames\n",
    "    for i in range(0, num_frames) :\n",
    "        ret, frame = video.read()\n",
    "\n",
    "    # End time\n",
    "    end = time.time()\n",
    "\n",
    "    # Time elapsed\n",
    "    seconds = end - start\n",
    "    print (\"Time taken : {0} seconds\".format(seconds))\n",
    "\n",
    "    # Calculate frames per second\n",
    "    fps  = num_frames / seconds\n",
    "    print(\"Estimated frames per second : {0}\".format(fps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ecea34",
   "metadata": {},
   "source": [
    "### 2D + 3D bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d85e135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theekshana/Documents/visualDet3D/visualDet3D/networks/lib/PSM_cost_volume.py:87: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  volatile= not self.training\n",
      "/home/theekshana/Documents/visualDet3D/visualDet3D/networks/lib/PSM_cost_volume.py:55: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  volatile= not self.training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True\n",
      "1 True\n",
      "2 True\n",
      "3 True\n",
      "4 True\n",
      "5 True\n",
      "6 True\n",
      "7 True\n",
      "8 True\n",
      "9 True\n",
      "10 True\n",
      "11 True\n",
      "12 True\n",
      "13 True\n",
      "14 True\n",
      "15 True\n",
      "16 True\n",
      "17 True\n",
      "18 True\n",
      "19 True\n",
      "20 True\n",
      "21 True\n",
      "22 True\n",
      "23 True\n",
      "24 True\n",
      "25 True\n",
      "26 True\n",
      "27 True\n",
      "28 True\n",
      "29 True\n",
      "30 True\n",
      "31 True\n",
      "32 True\n",
      "33 True\n",
      "34 True\n",
      "35 True\n",
      "36 True\n",
      "37 True\n",
      "38 True\n",
      "39 True\n",
      "40 True\n",
      "41 True\n",
      "42 True\n",
      "43 True\n",
      "44 True\n",
      "45 True\n",
      "46 True\n",
      "47 True\n",
      "48 True\n",
      "49 True\n",
      "50 True\n",
      "51 True\n",
      "52 True\n",
      "53 True\n",
      "54 True\n",
      "55 True\n",
      "56 True\n",
      "57 True\n",
      "58 True\n",
      "59 True\n",
      "60 True\n",
      "61 True\n",
      "62 True\n",
      "63 True\n",
      "64 True\n",
      "65 True\n",
      "66 True\n",
      "67 True\n",
      "68 True\n",
      "69 True\n",
      "70 True\n",
      "71 True\n",
      "72 True\n",
      "73 True\n",
      "74 True\n",
      "75 True\n",
      "76 True\n",
      "77 True\n",
      "78 True\n",
      "79 True\n",
      "80 True\n",
      "81 True\n",
      "82 True\n",
      "83 True\n",
      "84 True\n",
      "85 True\n",
      "86 True\n",
      "87 True\n",
      "88 True\n",
      "89 True\n",
      "90 True\n",
      "91 True\n",
      "92 True\n",
      "93 True\n",
      "94 True\n",
      "95 True\n",
      "96 True\n",
      "97 True\n",
      "98 True\n",
      "99 True\n",
      "100 True\n",
      "101 True\n",
      "102 True\n",
      "103 True\n",
      "104 True\n",
      "105 True\n",
      "106 True\n",
      "107 True\n",
      "108 True\n",
      "109 True\n",
      "110 True\n",
      "111 True\n",
      "112 True\n",
      "113 True\n",
      "114 True\n",
      "115 True\n",
      "116 True\n",
      "117 True\n",
      "118 True\n",
      "119 True\n",
      "120 True\n",
      "121 True\n",
      "122 True\n",
      "123 True\n",
      "124 True\n",
      "125 True\n",
      "126 True\n",
      "127 True\n",
      "128 True\n",
      "129 True\n",
      "130 True\n",
      "131 True\n",
      "132 True\n",
      "133 True\n",
      "134 True\n",
      "135 True\n",
      "136 True\n",
      "137 True\n",
      "138 True\n",
      "139 True\n",
      "140 True\n",
      "141 True\n",
      "142 True\n",
      "143 True\n",
      "144 True\n",
      "145 True\n",
      "146 True\n",
      "147 True\n",
      "148 True\n",
      "149 True\n",
      "150 True\n",
      "151 True\n",
      "152 True\n",
      "153 True\n",
      "154 True\n",
      "155 True\n",
      "156 True\n",
      "157 True\n",
      "158 True\n",
      "159 True\n",
      "160 True\n",
      "161 True\n",
      "162 True\n",
      "163 True\n",
      "164 True\n",
      "165 True\n",
      "166 True\n",
      "167 True\n",
      "168 True\n",
      "169 True\n",
      "170 True\n",
      "171 True\n",
      "172 True\n",
      "173 True\n",
      "174 True\n",
      "175 True\n",
      "176 True\n",
      "177 True\n",
      "178 True\n",
      "179 True\n",
      "180 True\n",
      "181 True\n",
      "182 True\n",
      "183 True\n",
      "184 True\n",
      "185 True\n",
      "186 True\n",
      "187 True\n",
      "188 True\n",
      "189 True\n",
      "190 True\n",
      "191 True\n",
      "192 True\n",
      "193 True\n",
      "194 True\n",
      "195 True\n",
      "196 True\n",
      "197 True\n",
      "198 True\n",
      "199 True\n",
      "200 True\n",
      "201 True\n",
      "202 True\n",
      "203 True\n",
      "204 True\n",
      "205 True\n",
      "206 True\n",
      "207 True\n",
      "208 True\n",
      "209 True\n",
      "210 True\n",
      "211 True\n",
      "212 True\n",
      "213 True\n",
      "214 True\n",
      "215 True\n",
      "216 True\n",
      "217 True\n",
      "218 True\n",
      "219 True\n",
      "220 True\n",
      "221 True\n",
      "222 True\n",
      "223 True\n",
      "224 True\n",
      "225 True\n",
      "226 True\n",
      "227 True\n",
      "228 True\n",
      "229 True\n",
      "230 True\n",
      "231 True\n",
      "232 True\n",
      "233 True\n",
      "234 True\n",
      "235 True\n",
      "236 True\n",
      "237 True\n",
      "238 True\n",
      "239 True\n",
      "240 True\n",
      "241 True\n",
      "242 True\n",
      "243 True\n",
      "244 True\n",
      "245 True\n",
      "246 True\n",
      "247 True\n",
      "248 True\n",
      "249 True\n",
      "250 True\n",
      "251 True\n",
      "252 True\n",
      "253 True\n",
      "254 True\n",
      "255 True\n",
      "256 True\n",
      "257 True\n",
      "258 True\n",
      "259 True\n",
      "260 True\n",
      "261 True\n",
      "262 True\n",
      "263 True\n",
      "264 True\n",
      "265 True\n",
      "266 True\n",
      "267 True\n",
      "268 True\n",
      "269 True\n",
      "270 True\n",
      "271 True\n",
      "272 True\n",
      "273 True\n",
      "274 True\n",
      "275 True\n",
      "276 True\n",
      "277 True\n",
      "278 True\n",
      "279 True\n",
      "280 True\n",
      "281 True\n",
      "282 True\n",
      "283 True\n",
      "284 True\n",
      "285 True\n",
      "286 True\n",
      "287 True\n",
      "288 True\n",
      "289 True\n",
      "290 True\n",
      "291 True\n",
      "292 True\n",
      "293 True\n",
      "294 True\n",
      "295 True\n",
      "296 True\n",
      "297 True\n",
      "298 True\n",
      "299 True\n",
      "300 True\n",
      "301 True\n",
      "302 True\n",
      "303 True\n",
      "304 True\n",
      "305 True\n",
      "306 True\n",
      "307 True\n",
      "308 True\n",
      "309 True\n",
      "310 True\n",
      "311 True\n",
      "312 True\n",
      "313 True\n",
      "314 True\n",
      "315 True\n",
      "316 True\n",
      "317 True\n",
      "318 True\n",
      "319 True\n",
      "320 True\n",
      "321 True\n",
      "322 True\n",
      "323 True\n",
      "324 True\n",
      "325 True\n",
      "326 True\n",
      "327 True\n",
      "328 True\n",
      "329 True\n",
      "330 True\n",
      "331 True\n",
      "332 True\n",
      "333 True\n",
      "334 True\n",
      "335 True\n",
      "336 True\n",
      "337 True\n",
      "338 True\n",
      "339 True\n",
      "340 True\n",
      "341 True\n",
      "342 True\n",
      "343 True\n",
      "344 True\n",
      "345 True\n",
      "346 True\n",
      "347 True\n",
      "348 True\n",
      "349 True\n",
      "350 True\n",
      "351 True\n",
      "352 True\n",
      "353 True\n",
      "354 True\n",
      "355 True\n",
      "356 True\n",
      "357 True\n",
      "358 True\n",
      "359 True\n",
      "360 True\n",
      "361 True\n",
      "362 True\n",
      "363 True\n",
      "364 True\n",
      "365 True\n",
      "366 True\n",
      "367 True\n",
      "368 True\n",
      "369 True\n",
      "370 True\n",
      "371 True\n",
      "372 True\n",
      "373 True\n",
      "374 True\n",
      "375 True\n",
      "376 True\n",
      "377 True\n",
      "378 True\n",
      "379 True\n",
      "380 True\n",
      "381 True\n",
      "382 True\n",
      "383 True\n",
      "384 True\n",
      "385 True\n",
      "386 True\n",
      "387 True\n",
      "388 True\n",
      "389 True\n",
      "390 True\n",
      "391 True\n",
      "392 True\n",
      "393 True\n",
      "394 True\n",
      "395 True\n",
      "396 True\n",
      "397 True\n",
      "398 True\n",
      "399 True\n",
      "400 True\n",
      "401 True\n",
      "402 True\n",
      "403 True\n",
      "404 True\n",
      "405 True\n",
      "406 True\n",
      "407 True\n",
      "408 True\n",
      "409 True\n",
      "410 True\n",
      "411 True\n",
      "412 True\n",
      "413 True\n",
      "414 True\n",
      "415 True\n",
      "416 True\n",
      "417 True\n",
      "418 True\n",
      "419 True\n",
      "420 True\n",
      "421 True\n",
      "422 True\n",
      "423 True\n",
      "424 True\n",
      "425 True\n",
      "426 True\n",
      "427 True\n",
      "428 True\n",
      "429 True\n",
      "430 True\n",
      "431 True\n",
      "432 True\n",
      "433 True\n",
      "434 True\n",
      "435 True\n",
      "436 True\n",
      "437 True\n",
      "438 True\n",
      "439 True\n",
      "440 True\n",
      "441 True\n",
      "442 True\n",
      "443 True\n",
      "444 True\n",
      "445 True\n",
      "446 True\n",
      "447 True\n",
      "448 True\n",
      "449 True\n",
      "450 True\n",
      "451 True\n",
      "452 True\n",
      "453 True\n",
      "454 True\n",
      "455 True\n",
      "456 True\n",
      "457 True\n",
      "458 True\n",
      "459 True\n",
      "460 True\n",
      "461 True\n",
      "462 True\n",
      "463 True\n",
      "464 True\n",
      "465 True\n",
      "466 True\n",
      "467 True\n",
      "468 True\n",
      "469 True\n",
      "470 True\n",
      "471 True\n",
      "472 True\n",
      "473 True\n",
      "474 True\n",
      "475 True\n",
      "476 True\n",
      "477 True\n",
      "478 True\n",
      "479 True\n",
      "480 True\n",
      "481 True\n",
      "482 True\n",
      "483 True\n",
      "484 True\n",
      "485 True\n",
      "486 True\n",
      "487 True\n",
      "488 True\n",
      "489 True\n",
      "490 True\n",
      "491 True\n",
      "492 True\n",
      "493 True\n",
      "494 True\n",
      "495 True\n",
      "496 True\n",
      "497 True\n",
      "498 True\n",
      "499 True\n",
      "500 True\n",
      "501 True\n",
      "502 True\n",
      "503 True\n",
      "504 True\n",
      "505 True\n",
      "506 True\n",
      "507 True\n",
      "508 True\n",
      "509 True\n",
      "510 True\n",
      "511 True\n",
      "512 True\n",
      "513 True\n",
      "514 True\n",
      "515 True\n",
      "516 True\n",
      "517 True\n",
      "518 True\n",
      "519 True\n",
      "520 True\n",
      "521 True\n",
      "522 True\n",
      "523 True\n",
      "524 True\n",
      "525 True\n",
      "526 True\n",
      "527 True\n",
      "528 True\n",
      "529 True\n",
      "530 True\n",
      "531 True\n",
      "532 True\n",
      "533 True\n",
      "534 True\n",
      "535 True\n",
      "536 True\n",
      "537 True\n",
      "538 True\n",
      "539 True\n",
      "540 True\n",
      "541 True\n",
      "542 True\n",
      "543 True\n",
      "544 True\n",
      "545 True\n",
      "546 True\n",
      "547 True\n",
      "548 True\n",
      "549 True\n",
      "550 True\n",
      "551 True\n",
      "552 True\n",
      "553 True\n",
      "554 True\n",
      "555 True\n",
      "556 True\n",
      "557 True\n",
      "558 True\n",
      "559 True\n",
      "560 True\n",
      "561 True\n",
      "562 True\n",
      "563 True\n",
      "564 True\n",
      "565 True\n",
      "566 True\n",
      "567 True\n",
      "568 True\n",
      "569 True\n",
      "570 True\n",
      "571 True\n",
      "572 True\n",
      "573 True\n",
      "574 True\n",
      "575 True\n",
      "576 True\n",
      "577 True\n",
      "578 True\n",
      "579 True\n",
      "580 True\n",
      "581 True\n",
      "582 True\n",
      "583 True\n",
      "584 True\n",
      "585 True\n",
      "586 True\n",
      "587 True\n",
      "588 True\n",
      "589 True\n",
      "590 True\n",
      "591 True\n",
      "592 True\n",
      "593 True\n",
      "594 True\n",
      "595 True\n",
      "596 True\n",
      "597 True\n",
      "598 True\n",
      "599 True\n",
      "600 True\n",
      "601 True\n",
      "602 True\n",
      "603 True\n",
      "604 True\n",
      "605 True\n",
      "606 True\n",
      "607 True\n",
      "608 True\n",
      "609 True\n",
      "610 True\n",
      "611 True\n",
      "612 True\n",
      "613 True\n",
      "614 True\n",
      "615 True\n",
      "616 True\n",
      "617 True\n",
      "618 True\n",
      "619 True\n",
      "620 True\n",
      "621 True\n",
      "622 True\n",
      "623 True\n",
      "624 True\n",
      "625 True\n",
      "626 True\n",
      "627 True\n",
      "628 True\n",
      "629 True\n",
      "630 True\n",
      "631 True\n",
      "632 True\n",
      "633 True\n",
      "634 True\n",
      "635 True\n",
      "636 True\n",
      "637 True\n",
      "638 True\n",
      "639 True\n",
      "640 True\n",
      "641 True\n",
      "642 True\n",
      "643 True\n",
      "644 True\n",
      "645 True\n",
      "646 True\n",
      "647 True\n",
      "648 True\n",
      "649 True\n",
      "650 True\n",
      "651 True\n",
      "652 True\n",
      "653 True\n",
      "654 True\n",
      "655 True\n",
      "656 True\n",
      "657 True\n",
      "658 True\n",
      "659 True\n",
      "660 True\n",
      "661 True\n",
      "662 True\n",
      "663 True\n",
      "664 True\n",
      "665 True\n",
      "666 True\n",
      "667 True\n",
      "668 True\n",
      "669 True\n",
      "670 True\n",
      "671 True\n",
      "672 True\n",
      "673 True\n",
      "674 True\n",
      "675 True\n",
      "676 True\n",
      "677 True\n",
      "678 True\n",
      "679 True\n",
      "680 True\n",
      "681 True\n",
      "682 True\n",
      "683 True\n",
      "684 True\n",
      "685 True\n",
      "686 True\n",
      "687 True\n",
      "688 True\n",
      "689 True\n",
      "690 True\n",
      "691 True\n",
      "692 True\n",
      "693 True\n",
      "694 True\n",
      "695 True\n",
      "696 True\n",
      "697 True\n",
      "698 True\n",
      "699 True\n",
      "700 True\n",
      "701 True\n",
      "702 True\n",
      "703 True\n",
      "704 True\n",
      "705 True\n",
      "706 True\n",
      "707 True\n",
      "708 True\n",
      "709 True\n",
      "710 True\n",
      "711 True\n",
      "712 True\n",
      "713 True\n",
      "714 True\n",
      "715 True\n",
      "716 True\n",
      "717 True\n",
      "718 True\n",
      "719 True\n",
      "720 True\n",
      "721 True\n",
      "722 True\n",
      "723 True\n",
      "724 True\n",
      "725 True\n",
      "726 True\n",
      "727 True\n",
      "728 True\n",
      "729 True\n",
      "730 True\n",
      "731 True\n",
      "732 True\n",
      "733 True\n",
      "734 True\n",
      "735 True\n",
      "736 True\n",
      "737 True\n",
      "738 True\n",
      "739 True\n",
      "740 True\n",
      "741 True\n",
      "742 True\n",
      "743 True\n",
      "744 True\n",
      "745 True\n",
      "746 True\n",
      "747 True\n",
      "748 True\n",
      "749 True\n",
      "750 True\n",
      "751 True\n",
      "752 True\n",
      "753 True\n",
      "754 True\n",
      "755 True\n",
      "756 True\n",
      "757 True\n",
      "758 True\n",
      "759 True\n",
      "760 True\n",
      "761 True\n",
      "762 True\n",
      "763 True\n",
      "764 True\n",
      "765 True\n",
      "766 True\n",
      "767 True\n",
      "768 True\n",
      "769 True\n",
      "770 True\n",
      "771 True\n",
      "772 True\n",
      "773 True\n",
      "774 True\n",
      "775 True\n",
      "776 True\n",
      "777 True\n",
      "778 True\n",
      "779 True\n",
      "780 True\n",
      "781 True\n",
      "782 True\n",
      "783 True\n",
      "784 True\n",
      "785 True\n",
      "786 True\n",
      "787 True\n",
      "788 True\n",
      "789 True\n",
      "790 True\n",
      "791 True\n",
      "792 True\n",
      "793 True\n",
      "794 True\n",
      "795 True\n",
      "796 True\n",
      "797 True\n",
      "798 True\n",
      "799 True\n",
      "800 True\n",
      "801 True\n",
      "802 True\n",
      "803 True\n",
      "804 True\n",
      "805 True\n",
      "806 True\n",
      "807 True\n",
      "808 True\n",
      "809 True\n",
      "810 True\n",
      "811 True\n",
      "812 True\n",
      "813 True\n",
      "814 True\n",
      "815 True\n",
      "816 True\n",
      "817 True\n",
      "818 True\n",
      "819 True\n",
      "820 True\n",
      "821 True\n",
      "822 True\n",
      "823 True\n",
      "824 True\n",
      "825 True\n",
      "826 True\n",
      "827 True\n",
      "828 True\n",
      "829 True\n",
      "830 True\n",
      "831 True\n",
      "832 True\n",
      "833 True\n",
      "834 True\n",
      "835 True\n",
      "836 True\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'seconds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e5211884d17f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Time elapsed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mseconds_2d3d\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mend_2d3d\u001b[0m  \u001b[0;34m-\u001b[0m \u001b[0mstart_2d3d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Time taken : {0} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseconds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Calculate frames per second\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seconds' is not defined"
     ]
    }
   ],
   "source": [
    "start_2d3d = time.time()\n",
    "\n",
    "for index in range(0,837):\n",
    "#     fig = plt.figure(figsize=(16,9))\n",
    "    a = compute_once(index, is_test_train=False, is_draw=False)\n",
    "#     clear_output(wait=True)\n",
    "#     plt.imshow(a)\n",
    "    print(index,cv2.imwrite(('data/2d3d %03d.png'%index), cv2.cvtColor(a, cv2.COLOR_RGB2BGR)))\n",
    "#     plt.xlabel(index)\n",
    "#     plt.show()\n",
    "         \n",
    "end_2d3d = time.time()\n",
    "# Time elapsed\n",
    "seconds_2d3d  = end_2d3d  - start_2d3d \n",
    "print (\"Time taken : {0} seconds\".format(seconds_2d3d))\n",
    "\n",
    "# Calculate frames per second\n",
    "fps_2d3d  = 837 / seconds_2d3d\n",
    "print(\"Estimated frames per second : {0}\".format(fps_2d3d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dc2272",
   "metadata": {},
   "source": [
    "### 3D bounding boxes Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "640369e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chirathv97/FYP/visualDet3D/visualDet3D/networks/lib/PSM_cost_volume.py:87: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  volatile= not self.training\n",
      "/home/chirathv97/FYP/visualDet3D/visualDet3D/networks/lib/PSM_cost_volume.py:55: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  volatile= not self.training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken : 104.29294514656067 seconds\n",
      "Estimated frames per second : 8.02547093500698\n"
     ]
    }
   ],
   "source": [
    "start_3d = time.time()\n",
    "for index in range(0,837):\n",
    "#     fig = plt.figure(figsize=(16,9))\n",
    "    a = compute_once_3d_bounding_box_only(index, is_test_train=False, is_draw=False)\n",
    "#     clear_output(wait=True)\n",
    "#     plt.imshow(a)\n",
    "#     print(index,cv2.imwrite(('data/3d %03d.png'%index), cv2.cvtColor(a, cv2.COLOR_RGB2BGR)))\n",
    "#     plt.xlabel(index)\n",
    "#     plt.show()\n",
    "         \n",
    "end_3d = time.time()\n",
    "# Time elapsed\n",
    "seconds_3d = end_3d - start_3d\n",
    "print (\"Time taken : {0} seconds\".format(seconds_3d))\n",
    "\n",
    "# Calculate frames per second\n",
    "fps_3d  = 837 / seconds_3d\n",
    "print(\"Estimated frames per second : {0}\".format(fps_3d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2796ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1684411991.236658\n",
      "1684412114.617281\n",
      "123.38062286376953\n",
      "6.783885350653254\n"
     ]
    }
   ],
   "source": [
    "print(start_3d)\n",
    "print(end_3d)\n",
    "print(seconds_3d)\n",
    "print(fps_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83d90d6",
   "metadata": {},
   "source": [
    "hdd laptop\n",
    "1680770171.802954\n",
    "1680771943.199522\n",
    "1771.3965680599213\n",
    "0.4725085365366287"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46304417",
   "metadata": {},
   "source": [
    "### 3D bounding boxes + Track ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6fd70df",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chirathv97/anaconda3/envs/yolo3dpy37/lib/python3.7/site-packages/matplotlib/cbook/__init__.py:701: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = np.array(x, subok=True, copy=copy)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-13cde77f767d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massignTrackID\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chirathv97/anaconda3/envs/yolo3dpy37/lib/python3.7/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Don't modify *func*'s signature, as boilerplate.py needs it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chirathv97/anaconda3/envs/yolo3dpy37/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2655\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m   2658\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chirathv97/anaconda3/envs/yolo3dpy37/lib/python3.7/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Don't modify *func*'s signature, as boilerplate.py needs it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chirathv97/anaconda3/envs/yolo3dpy37/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1412\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chirathv97/anaconda3/envs/yolo3dpy37/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5485\u001b[0m                               **kwargs)\n\u001b[1;32m   5486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/chirathv97/anaconda3/envs/yolo3dpy37/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[1;32m    706\u001b[0m             raise TypeError(\"Image data of dtype {} cannot be converted to \"\n\u001b[0;32m--> 707\u001b[0;31m                             \"float\".format(self._A.dtype))\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data of dtype object cannot be converted to float"
     ]
    }
   ],
   "source": [
    "start_track = time.time()\n",
    "\n",
    "for index in range(0,5):\n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    a = assignTrackID(index)\n",
    "    clear_output(wait=True)\n",
    "    plt.imshow(a)\n",
    "    plt.xlabel(index)\n",
    "    plt.show()\n",
    "#     print(index,cv2.imwrite(('data/track %03d.png'%index), cv2.cvtColor(a, cv2.COLOR_RGB2BGR)))\n",
    "end_track = time.time()\n",
    "\n",
    "\n",
    "# Time elapsed\n",
    "seconds_track = end_track - start_track\n",
    "print (\"Time taken : {0} seconds\".format(seconds_track))\n",
    "\n",
    "# Calculate frames per second\n",
    "fps_track  = 837 / seconds_track\n",
    "print(\"Estimated frames per second : {0}\".format(fps_track))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6532d1f3",
   "metadata": {},
   "source": [
    "hdd laptop\n",
    "Time taken : 47.59913086891174 seconds\n",
    "Estimated frames per second : 17.584354687170705"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5688f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(start_track)\n",
    "print(end_track)\n",
    "print(seconds_track)\n",
    "print(fps_track)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
