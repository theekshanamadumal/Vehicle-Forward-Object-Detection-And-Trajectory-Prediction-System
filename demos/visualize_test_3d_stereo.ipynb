{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../config/kitti_stereo.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b2144950f00c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CUDA available: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../config/kitti_stereo.py\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mis_test_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/theekshana/Documents/visualDet3D/visualDet3D/utils/utils.py\u001b[0m in \u001b[0;36mcfg_from_file\u001b[0;34m(cfg_filename)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mtemp_config_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNamedTemporaryFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_config_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mtemp_config_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_config_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_config_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_config_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mtemp_module_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_config_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_config_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/theekshana/anaconda3/envs/YOLO3D/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../config/kitti_stereo.py'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import importlib\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, models, transforms\n",
    "import torchvision\n",
    "from visualDet3D.data.kitti.utils import write_result_to_file\n",
    "from visualDet3D.utils.utils import LossLogger, cfg_from_file\n",
    "from visualDet3D.networks.utils.registry import DETECTOR_DICT, DATASET_DICT, PIPELINE_DICT\n",
    "from visualDet3D.networks.heads.anchors import Anchors\n",
    "from visualDet3D.networks.lib.fast_utils.hill_climbing import post_opt\n",
    "from visualDet3D.networks.utils import BBox3dProjector, BackProjection\n",
    "from visualDet3D.utils.utils import convertAlpha2Rot, convertRot2Alpha, draw_3D_box, compound_annotation\n",
    "import visualDet3D.data.kitti.dataset\n",
    "from visualDet3D.utils.timer import Timer\n",
    "from numba import jit\n",
    "from tqdm import tqdm\n",
    "print('CUDA available: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "cfg = cfg_from_file(\"../config/kitti_stereo.py\")\n",
    "is_test_train = True\n",
    "\n",
    "checkpoint_name = \"open_Stereo3D_latest.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox2d_to_image(image, bboxes2d, color=(255, 0, 255)):\n",
    "    drawed_image = image.copy()\n",
    "    for box2d in bboxes2d:\n",
    "        cv2.rectangle(drawed_image, (int(box2d[0]), int(box2d[1])), (int(box2d[2]), int(box2d[3])), color, 3)\n",
    "    return drawed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcfg\u001b[49m\u001b[38;5;241m.\u001b[39mbatch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      2\u001b[0m split_to_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m is_test_train \u001b[38;5;241m=\u001b[39m split_to_test \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "cfg.batch_size=1\n",
    "split_to_test='validation'\n",
    "\n",
    "is_test_train = split_to_test == 'training'\n",
    "if split_to_test == 'training':\n",
    "    dataset_name = cfg.data.train_dataset\n",
    "elif split_to_test == 'test':\n",
    "    dataset_name = cfg.data.test_dataset\n",
    "else:\n",
    "    dataset_name = cfg.data.val_dataset\n",
    "\n",
    "dataset = DATASET_DICT[dataset_name](\n",
    "        cfg, split_to_test\n",
    "        )\n",
    "\n",
    "if split_to_test=='training':\n",
    "    dataset_val = DATASET_DICT[cfg.data.val_dataset](\n",
    "            cfg, 'validation'\n",
    "            )\n",
    "    dataset.transform = dataset_val.transform\n",
    "    dataset.collate_fn = dataset_val.collate_fn\n",
    "\n",
    "\n",
    "\n",
    "detector = DETECTOR_DICT[cfg.detector.name](cfg.detector)\n",
    "detector = detector.cuda()\n",
    "\n",
    "weight_path = os.path.join(cfg.path.checkpoint_path, checkpoint_name)\n",
    "state_dict = torch.load(weight_path, map_location='cuda:{}'.format(cfg.trainer.gpu))\n",
    "new_dict = state_dict.copy()\n",
    "for key in state_dict:\n",
    "    if 'focalLoss' in key:\n",
    "        new_dict.pop(key)\n",
    "detector.load_state_dict(new_dict, strict=False)\n",
    "detector.eval().cuda()\n",
    "\n",
    "# testing pipeline\n",
    "test_func = PIPELINE_DICT[cfg.trainer.test_func]\n",
    "\n",
    "projector = BBox3dProjector().cuda()\n",
    "backprojector = BackProjection().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     new_image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray((image \u001b[38;5;241m*\u001b[39m cfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39maugmentation\u001b[38;5;241m.\u001b[39mrgb_std \u001b[38;5;241m+\u001b[39m  cfg\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39maugmentation\u001b[38;5;241m.\u001b[39mrgb_mean) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_image\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;129m@jit\u001b[39m(cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, nopython\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mToColorDepth\u001b[39m(depth_image:np\u001b[38;5;241m.\u001b[39mndarray)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mnp\u001b[38;5;241m.\u001b[39mndarray: \u001b[38;5;66;03m#[H, W] -> [H, W, 3] # Used to draw depth predictions\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     H, W \u001b[38;5;241m=\u001b[39m depth_image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     21\u001b[0m     max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39mmax(depth_image))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'jit' is not defined"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "def corner_homo2bbox(corner_homo):\n",
    "    \"\"\"\n",
    "        corner_homo: [N, 8, 3]\n",
    "    \"\"\"\n",
    "    min_xy  = torch.min(corner_homo[:, :, 0:2], dim=1)[0]\n",
    "    max_xy  = torch.max(corner_homo[:, :, 0:2], dim=1)[0]\n",
    "    min_xy[:, 0]  = torch.clamp(min_xy[:, 0], 0, cfg.rgb_shape[1])\n",
    "    min_xy[:, 1]  = torch.clamp(min_xy[:, 1], 0, cfg.rgb_shape[0])\n",
    "    max_xy[:, 0]  = torch.clamp(max_xy[:, 0], 0, cfg.rgb_shape[1])\n",
    "    max_xy[:, 1]  = torch.clamp(max_xy[:, 1], 0, cfg.rgb_shape[0])\n",
    "    return torch.cat([min_xy, max_xy], dim=1)\n",
    "\n",
    "def denorm(image):\n",
    "    new_image = np.array((image * cfg.data.augmentation.rgb_std +  cfg.data.augmentation.rgb_mean) * 255, dtype=np.uint8)\n",
    "    return new_image\n",
    "\n",
    "@jit(cache=True, nopython=True)\n",
    "def ToColorDepth(depth_image:np.ndarray)->np.ndarray: #[H, W] -> [H, W, 3] # Used to draw depth predictions\n",
    "    H, W = depth_image.shape\n",
    "    max_depth = float(np.max(depth_image))\n",
    "    cmap = np.array([\n",
    "        [0,0,0,114],[0,0,1,185],[1,0,0,114],[1,0,1,174], \n",
    "        [0,1,0,114],[0,1,1,185],[1,1,0,114],[1,1,1,0]\n",
    "    ])\n",
    "    _sum  = 0\n",
    "    for i in range(8):\n",
    "        _sum += cmap[i, 3]\n",
    "    \n",
    "    weights = np.zeros(8)\n",
    "    cumsum = np.zeros(8)\n",
    "    for i in range(7):\n",
    "        weights[i] = _sum / cmap[i, 3]\n",
    "        cumsum[i+1] = cumsum[i] + cmap[i, 3] / _sum\n",
    "    \n",
    "    image = np.zeros((H, W, 3), dtype=np.uint8)\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            val = depth_image[i, j] / max_depth\n",
    "            for k in range(7):\n",
    "                if val <= cumsum[k + 1]:\n",
    "                    break\n",
    "            w = 1.0- (val - cumsum[k]) * weights[k]\n",
    "            r = int( (w * cmap[k, 0] + (1 - w) * cmap[k+1, 0]) * 255 )\n",
    "            g = int( (w * cmap[k, 1] + (1 - w) * cmap[k+1, 1]) * 255 )\n",
    "            b = int( (w * cmap[k, 2] + (1 - w) * cmap[k+1, 2]) * 255 )\n",
    "            image[i, j] = np.array([r,g,b])\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_once(index, is_draw=True, is_test_train=True):\n",
    "    name = \"%06d\" % index\n",
    "    data = dataset[index]\n",
    "    if isinstance(data['calib'], list):\n",
    "        P2 = data['calib'][0]\n",
    "    else:\n",
    "        P2 = data['calib']\n",
    "    original_height = data['original_shape'][0]\n",
    "    collated_data = dataset.collate_fn([data])\n",
    "    height = collated_data[0].shape[2]\n",
    "    scale_2d = (original_height - cfg.data.augmentation.crop_top) / height\n",
    "    \n",
    "    if len(collated_data) > 6:\n",
    "        left_images, right_images, _, _, labels, bbox_3d, _ = collated_data\n",
    "    else:\n",
    "        left_images, right_images, _, _, labels, bbox_3d = collated_data\n",
    "    image = left_images\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        left_images, right_images, P2, P3 = collated_data[0], collated_data[1], collated_data[2], collated_data[3]\n",
    "        scores, bbox, obj_names = detector([left_images.cuda().float().contiguous(),\n",
    "                                          right_images.cuda().float().contiguous(),\n",
    "                                          P2.cuda().float(),\n",
    "                                          P3.cuda().float()])\n",
    "        \n",
    "        P2 = P2[0]\n",
    "        bbox_2d = bbox[:, 0:4]\n",
    "        bbox_3d_state = bbox[:, 4:] #[cx,cy,z,w,h,l,alpha]\n",
    "        bbox_3d_state_3d = backprojector(bbox_3d_state, P2.cuda()) #[x, y, z, w,h ,l, alpha]\n",
    "        abs_bbox, bbox_3d_corner_homo, thetas = projector(bbox_3d_state_3d, P2.cuda())\n",
    "\n",
    "            \n",
    "    \n",
    "    rgb_image = denorm(image[0].cpu().numpy().transpose([1, 2, 0]))\n",
    "    if len(scores) > 0:\n",
    "        rgb_image = draw_bbox2d_to_image(rgb_image, bbox_2d.cpu().numpy())\n",
    "        for box in bbox_3d_corner_homo:\n",
    "            box = box.cpu().numpy().T\n",
    "            rgb_image = draw_3D_box(rgb_image, box)\n",
    "    if is_draw:\n",
    "        plt.imshow(np.clip(rgb_image, 0, 255))\n",
    "\n",
    "    return np.clip(rgb_image, 0, 255)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "centers = np.array([[1.50, 1.57, 1.625, 1.67, 1.72],\n",
    "                    [1.42, 1.46,  1.50, 1.58, 1.66],\n",
    "                    [3.43, 3.63,  3.89, 4.17, 4.47]]) #[3, 5]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 2\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m, in \u001b[0;36mcompute_once\u001b[1;34m(index, is_draw, is_test_train)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_once\u001b[39m(index, is_draw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, is_test_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%06d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m index\n\u001b[1;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m[index]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalib\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m      5\u001b[0m         P2 \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalib\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "a = compute_once(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m16\u001b[39m,\u001b[38;5;241m9\u001b[39m))\n\u001b[0;32m      3\u001b[0m index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 4\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_test_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_draw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m, in \u001b[0;36mcompute_once\u001b[1;34m(index, is_draw, is_test_train)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_once\u001b[39m(index, is_draw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, is_test_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%06d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m index\n\u001b[1;32m----> 3\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m[index]\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalib\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m      5\u001b[0m         P2 \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalib\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "fig = plt.figure(figsize=(16,9))\n",
    "index += 1\n",
    "a = compute_once(index, is_test_train=False, is_draw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
